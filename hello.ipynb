{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a452e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ️ XGBoost imported, but no CUDA detected - using CPU\n",
      "⚠️ CuPy/cuDF not available, using CPU arrays\n",
      "⚠️ No GPU detected, running on CPU\n",
      "================================================================================\n",
      "AI-DRIVEN RISK PREDICTION ENGINE FOR CHRONIC CARE PATIENTS (GPU-ACCELERATED + TEST VALIDATION)\n",
      "================================================================================\n",
      "\n",
      "🔄 Loading and preprocessing TRAINING dataset...\n",
      "📊 Training dataset shape: (81410, 152)\n",
      "\n",
      "🔄 Loading TEST dataset for final validation...\n",
      "📊 Test dataset shape: (20353, 152)\n",
      "🎯 Original target distribution (Training):\n",
      "readmitted\n",
      "0    0.53857\n",
      "1    0.46143\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "🔧 Engineering improved target variable...\n",
      "🎯 Enhanced target distribution (Training):\n",
      "high_risk_90d\n",
      "0    0.828424\n",
      "1    0.171576\n",
      "Name: proportion, dtype: float64\n",
      "🎯 Enhanced target distribution (Test):\n",
      "high_risk_90d\n",
      "0    0.826463\n",
      "1    0.173537\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "🧬 Creating advanced clinical features...\n",
      "📈 Training features after enhancement: 171\n",
      "📈 Test features after enhancement: 171\n",
      "\n",
      "🎯 Performing intelligent feature selection...\n",
      "🧹 Sanitizing feature names for XGBoost compatibility...\n",
      "✅ Sanitized 168 feature names\n",
      "✅ Selected 50 most informative features\n",
      "\n",
      "🔧 Preparing test data with same preprocessing pipeline...\n",
      "✅ Test data prepared with same 50 features\n",
      "\n",
      "📊 Development split:\n",
      "  Training set: (65128, 50), Positive class: 0.172\n",
      "  Validation set: (16282, 50), Positive class: 0.172\n",
      "  True Test set: (20353, 50), Positive class: 0.174\n",
      "\n",
      "🚀 Training GPU-accelerated models...\n",
      "🔄 After SMOTE: (107908, 50), Positive class: 0.500\n",
      "\n",
      "🔄 Training XGBoost_CPU...\n",
      "  Validation Accuracy: 0.890\n",
      "  Validation ROC-AUC: 0.950\n",
      "  Validation PR-AUC: 0.720\n",
      "  Validation F1-Score: 0.747\n",
      "  ⏱️ Training Time: 2.95 seconds\n",
      "\n",
      "🔄 Training Random_Forest_Optimized...\n",
      "  Validation Accuracy: 0.892\n",
      "  Validation ROC-AUC: 0.952\n",
      "  Validation PR-AUC: 0.731\n",
      "  Validation F1-Score: 0.751\n",
      "  ⏱️ Training Time: 25.71 seconds\n",
      "\n",
      "🤝 Creating GPU-accelerated ensemble...\n",
      "🔄 Cross-validating XGBoost_CPU...\n",
      "  CV Score: 0.951 (±0.001) - Time: 17.50s\n",
      "🔄 Cross-validating Random_Forest_Optimized...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/ensemble/_forest.py:861: UserWarning: class_weight presets \"balanced\" or \"balanced_subsample\" are not recommended for warm_start if the fitted data differs from the full dataset. In order to use \"balanced\" weights, use compute_class_weight (\"balanced\", classes, y). In place of y you can use a large enough sample of the full training set target to properly estimate the class frequency distributions. Pass the resulting weights as the class_weight parameter.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CV Score: 0.987 (±0.018) - Time: 100.45s\n",
      "🎯 Ensemble weights:\n",
      "  XGBoost_CPU: 0.491\n",
      "  Random_Forest_Optimized: 0.509\n",
      "  ⏱️ Ensemble Time: 0.01 seconds\n",
      "\n",
      "================================================================================\n",
      "🔥 EVALUATING ON TRUE UNSEEN TEST DATASET\n",
      "================================================================================\n",
      "\n",
      "🎯 Testing XGBoost_CPU on unseen data...\n",
      "  🎯 TEST Accuracy: 0.892\n",
      "  🎯 TEST ROC-AUC: 0.952\n",
      "  🎯 TEST PR-AUC: 0.733\n",
      "  🎯 TEST F1-Score: 0.752\n",
      "\n",
      "🎯 Testing Random_Forest_Optimized on unseen data...\n",
      "  🎯 TEST Accuracy: 0.895\n",
      "  🎯 TEST ROC-AUC: 0.953\n",
      "  🎯 TEST PR-AUC: 0.744\n",
      "  🎯 TEST F1-Score: 0.755\n",
      "\n",
      "🎯 Testing Ensemble on unseen data...\n",
      "  🎯 TEST Accuracy: 0.894\n",
      "  🎯 TEST ROC-AUC: 0.954\n",
      "  🎯 TEST PR-AUC: 0.748\n",
      "  🎯 TEST F1-Score: 0.754\n",
      "\n",
      "================================================================================\n",
      "COMPREHENSIVE MODEL PERFORMANCE ANALYSIS\n",
      "================================================================================\n",
      "📊 Model Performance Comparison:\n",
      "                  Model  Val_Accuracy  Val_ROC_AUC  Val_F1_Score  Test_Accuracy  Test_ROC_AUC  Test_F1_Score  Training_Time\n",
      "            XGBoost_CPU         0.890        0.950         0.747          0.892         0.952          0.752          2.952\n",
      "Random_Forest_Optimized         0.892        0.952         0.751          0.895         0.953          0.755         25.710\n",
      "           Ensemble_GPU         0.892        0.953         0.751          0.894         0.954          0.754          0.007\n",
      "\n",
      "🏆 Best performing model on TEST data: Ensemble_GPU (Test ROC-AUC: 0.954)\n",
      "\n",
      "🎯 Generating feature importance analysis...\n",
      "Top 20 Most Important Features:\n",
      "        original_feature_name  importance_score  importance_rank\n",
      "    total_healthcare_contacts          0.181772               37\n",
      "             number_inpatient          0.160109                7\n",
      "          inpatient_intensity          0.107573               39\n",
      "             number_emergency          0.094842                6\n",
      "     emergency_to_total_ratio          0.090615               38\n",
      "                high_utilizer          0.074944               40\n",
      "                 A1Cresult:>8          0.048356               30\n",
      "        diabetes_control_poor          0.041596               41\n",
      "    diabetes_control_moderate          0.035015               42\n",
      "               A1Cresult:None          0.018534               31\n",
      "            number_outpatient          0.015301                5\n",
      "admission_source_id:Emergency          0.012123               15\n",
      "                   insulin:No          0.010994               27\n",
      " admission_source_id:Referral          0.009334               16\n",
      "           max_glu_serum:>300          0.008593               33\n",
      "            total_med_changes          0.007360               35\n",
      "           insulin_complexity          0.006591               36\n",
      "                       change          0.005590                9\n",
      "              diag_1:Diabetes          0.004743               21\n",
      "                 metformin:No          0.004683               24\n",
      "\n",
      "📋 Generating 10K entry CSV with final trained model and requested columns...\n",
      "🔄 Training final production model on full training dataset...\n",
      "💾 Saved model to: models/final_model.joblib\n",
      "💾 Saved pipeline to: models/pipeline_artifacts.joblib\n",
      "📋 Adding requested columns to final dataset...\n",
      "⚠️ Column not found: total_visits (sanitized: total_visits)\n",
      "✅ Added column: number_diagnoses (from number_diagnoses)\n",
      "⚠️ Column not found: diagnoses_log (sanitized: diagnoses_log)\n",
      "✅ Added column: num_lab_procedures (from num_lab_procedures)\n",
      "✅ Added column: time_in_hospital (from time_in_hospital)\n",
      "✅ Added column: age:70+ (from age_70)\n",
      "📊 Successfully added 4 requested columns: ['number_diagnoses', 'num_lab_procedures', 'time_in_hospital', 'age:70+']\n",
      "✅ Generated risk_prediction_10k_validated_GPU_with_additional_cols.csv with 10000 entries\n",
      "📊 Total columns in CSV: 68\n",
      "\n",
      "================================================================================\n",
      "🎯 FINAL RISK PREDICTION ENGINE RESULTS WITH ADDITIONAL COLUMNS\n",
      "================================================================================\n",
      "🏆 Best Model: Ensemble_GPU\n",
      "📊 Validation Performance:\n",
      "  Accuracy: 89.2%\n",
      "  ROC-AUC: 0.953\n",
      "  F1-Score: 0.751\n",
      "🎯 TRUE TEST Performance:\n",
      "  Accuracy: 89.4%\n",
      "  ROC-AUC: 0.954\n",
      "  F1-Score: 0.754\n",
      "📈 Generalization Gap (Val-Test ROC-AUC): 0.001\n",
      "✅ EXCELLENT: Model generalizes very well to unseen data!\n",
      "\n",
      "⚡ Performance Summary:\n",
      "  Total Training Time: 28.66 seconds\n",
      "  Final Model Training: 7.32 seconds\n",
      "  10K Predictions: 0.08 seconds\n",
      "\n",
      "📁 Final Outputs:\n",
      "  ✅ risk_prediction_10k_validated_GPU_with_additional_cols.csv - 10K validated predictions with additional columns\n",
      "  ✅ Model validated on true test set\n",
      "  ✅ Top 20 features identified and included\n",
      "  ✅ Requested additional columns: ['number_diagnoses', 'num_lab_procedures', 'time_in_hospital', 'age:70+']\n",
      "  ✅ GPU acceleration utilized\n",
      "\n",
      "🎉 SUCCESS: Risk prediction engine ready for production deployment with enhanced dataset!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ======= AI-Driven Risk Prediction Engine for Chronic Care (GPU-Accelerated + Test Validation + Additional Columns) =======\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, confusion_matrix,\n",
    "                            accuracy_score, f1_score, classification_report,\n",
    "                            precision_recall_curve, roc_curve)\n",
    "from sklearn.calibration import calibration_curve # Import calibration_curve\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "import time\n",
    "\n",
    "# GPU-specific imports\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGB_IMPORTED = True\n",
    "except ImportError:\n",
    "    XGB_IMPORTED = False\n",
    "\n",
    "# GPU is available only if CUDA is present and xgboost is imported\n",
    "GPU_AVAILABLE = False\n",
    "try:\n",
    "    import torch\n",
    "    GPU_AVAILABLE = bool(XGB_IMPORTED and torch.cuda.is_available())\n",
    "except Exception:\n",
    "    GPU_AVAILABLE = False\n",
    "\n",
    "if XGB_IMPORTED and GPU_AVAILABLE:\n",
    "    print(\"🚀 XGBoost imported and CUDA detected - GPU acceleration enabled!\")\n",
    "elif XGB_IMPORTED:\n",
    "    print(\"ℹ️ XGBoost imported, but no CUDA detected - using CPU\")\n",
    "else:\n",
    "    print(\"⚠️ XGBoost not available, falling back to CPU alternatives\")\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    import cudf\n",
    "    CUPY_AVAILABLE = True\n",
    "    print(\"🚀 CuPy and cuDF loaded successfully!\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ CuPy/cuDF not available, using CPU arrays\")\n",
    "    CUPY_AVAILABLE = False\n",
    "\n",
    "# Check GPU availability\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎯 GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"🎯 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ No GPU detected, running on CPU\")\n",
    "\n",
    "# ======= Feature Name Sanitization Function =======\n",
    "def sanitize_feature_names(feature_names):\n",
    "    \"\"\"\n",
    "    Sanitize feature names to be compatible with XGBoost\n",
    "    Replace problematic characters with safe alternatives\n",
    "    \"\"\"\n",
    "    sanitized_names = []\n",
    "    for name in feature_names:\n",
    "        # Replace problematic characters\n",
    "        clean_name = str(name)\n",
    "        clean_name = re.sub(r'[<>[\\]]', '_', clean_name)  # Replace <, >, [, ] with _\n",
    "        clean_name = re.sub(r':', '_', clean_name)        # Replace : with _\n",
    "        clean_name = re.sub(r'[^\\w_]', '_', clean_name)   # Replace any other non-alphanumeric chars with _\n",
    "        clean_name = re.sub(r'_+', '_', clean_name)       # Replace multiple underscores with single\n",
    "        clean_name = clean_name.strip('_')                # Remove leading/trailing underscores\n",
    "\n",
    "        # Ensure it doesn't start with a number\n",
    "        if clean_name and clean_name[0].isdigit():\n",
    "            clean_name = 'feat_' + clean_name\n",
    "\n",
    "        # Handle empty names\n",
    "        if not clean_name:\n",
    "            clean_name = f'feature_{len(sanitized_names)}'\n",
    "\n",
    "        sanitized_names.append(clean_name)\n",
    "\n",
    "    return sanitized_names\n",
    "\n",
    "# ======= 1. Enhanced Data Loading and Target Engineering =======\n",
    "print(\"=\"*80)\n",
    "print(\"AI-DRIVEN RISK PREDICTION ENGINE FOR CHRONIC CARE PATIENTS (GPU-ACCELERATED + TEST VALIDATION)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n🔄 Loading and preprocessing TRAINING dataset...\")\n",
    "ds = load_dataset(\"imodels/diabetes-readmission\")\n",
    "df_train = pd.DataFrame(ds['train'])\n",
    "df_train['patient_id'] = range(1, len(df_train)+1)\n",
    "\n",
    "print(f\"📊 Training dataset shape: {df_train.shape}\")\n",
    "\n",
    "# Load test dataset\n",
    "print(\"\\n🔄 Loading TEST dataset for final validation...\")\n",
    "try:\n",
    "    df_test_raw = pd.DataFrame(ds['test'])\n",
    "    df_test_raw['patient_id'] = range(1, len(df_test_raw)+1)\n",
    "    print(f\"📊 Test dataset shape: {df_test_raw.shape}\")\n",
    "    TEST_AVAILABLE = True\n",
    "except:\n",
    "    print(\"⚠️ Test dataset not available, will use train/validation split only\")\n",
    "    TEST_AVAILABLE = False\n",
    "\n",
    "print(f\"🎯 Original target distribution (Training):\\n{df_train['readmitted'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ======= 2. Advanced Target Variable Engineering =======\n",
    "print(\"\\n🔧 Engineering improved target variable...\")\n",
    "\n",
    "def create_risk_target(df):\n",
    "    \"\"\"Create a more nuanced risk target combining multiple factors\"\"\"\n",
    "    risk_score = 0\n",
    "\n",
    "    # Readmission risk (primary)\n",
    "    if 'readmitted' in df.columns:\n",
    "        risk_score += df['readmitted'] * 0.4\n",
    "\n",
    "    # High utilization risk\n",
    "    if 'number_emergency' in df.columns:\n",
    "        risk_score += (df['number_emergency'] > 0).astype(int) * 0.2\n",
    "\n",
    "    if 'number_inpatient' in df.columns:\n",
    "        risk_score += (df['number_inpatient'] > 1).astype(int) * 0.15\n",
    "\n",
    "    # Clinical deterioration indicators\n",
    "    if 'A1Cresult:>8' in df.columns:\n",
    "        risk_score += df['A1Cresult:>8'] * 0.15\n",
    "\n",
    "    if 'max_glu_serum:>300' in df.columns:\n",
    "        risk_score += df['max_glu_serum:>300'] * 0.1\n",
    "\n",
    "    # Convert to binary high-risk (>= 0.5) vs low-risk\n",
    "    return (risk_score >= 0.5).astype(int)\n",
    "\n",
    "# Create enhanced target for training set\n",
    "df_train['high_risk_90d'] = create_risk_target(df_train)\n",
    "print(f\"🎯 Enhanced target distribution (Training):\\n{df_train['high_risk_90d'].value_counts(normalize=True)}\")\n",
    "\n",
    "# Create enhanced target for test set if available\n",
    "if TEST_AVAILABLE:\n",
    "    df_test_raw['high_risk_90d'] = create_risk_target(df_test_raw)\n",
    "    print(f\"🎯 Enhanced target distribution (Test):\\n{df_test_raw['high_risk_90d'].value_counts(normalize=True)}\")\n",
    "\n",
    "# ======= 3. Advanced Clinical Feature Engineering =======\n",
    "print(\"\\n🧬 Creating advanced clinical features...\")\n",
    "\n",
    "def create_advanced_clinical_features(df):\n",
    "    \"\"\"Create sophisticated clinical risk features\"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # === Medication Complexity Score ===\n",
    "    medication_cols = [col for col in df.columns if any(med in col.lower()\n",
    "                      for med in ['insulin', 'metformin', 'glyburide', 'glipizide', 'glimepiride'])]\n",
    "\n",
    "    if medication_cols:\n",
    "        # Count medication changes\n",
    "        df['total_med_changes'] = 0\n",
    "        for col in medication_cols:\n",
    "            if ':Up' in col or ':Down' in col:\n",
    "                df['total_med_changes'] += df[col]\n",
    "\n",
    "        # Insulin management complexity\n",
    "        insulin_cols = [col for col in medication_cols if 'insulin' in col.lower()]\n",
    "        if insulin_cols:\n",
    "            df['insulin_complexity'] = sum(df[col] for col in insulin_cols if ':Up' in col or ':Down' in col)\n",
    "\n",
    "    # === Comorbidity Burden Score ===\n",
    "    diag_cols = [col for col in df.columns if col.startswith('diag_')]\n",
    "    if diag_cols:\n",
    "        df['comorbidity_count'] = sum(df[col] for col in diag_cols)\n",
    "\n",
    "        # Specific high-risk conditions\n",
    "        high_risk_conditions = ['Circulatory', 'Diabetes', 'Neoplasms']\n",
    "        df['high_risk_comorbidities'] = 0\n",
    "        for condition in high_risk_conditions:\n",
    "            condition_cols = [col for col in diag_cols if condition in col]\n",
    "            if condition_cols:\n",
    "                df['high_risk_comorbidities'] += sum(df[col] for col in condition_cols)\n",
    "\n",
    "    # === Healthcare Utilization Pattern ===\n",
    "    if all(col in df.columns for col in ['number_inpatient', 'number_outpatient', 'number_emergency']):\n",
    "        df['total_healthcare_contacts'] = df['number_inpatient'] + df['number_outpatient'] + df['number_emergency']\n",
    "        df['emergency_to_total_ratio'] = df['number_emergency'] / (df['total_healthcare_contacts'] + 1)\n",
    "        df['inpatient_intensity'] = df['number_inpatient'] / (df['total_healthcare_contacts'] + 1)\n",
    "\n",
    "        # High utilizer flag (top 25%) - Use training data quantiles for consistency\n",
    "        if 'quantile_75' not in globals():\n",
    "            global quantile_75\n",
    "            quantile_75 = df['total_healthcare_contacts'].quantile(0.75)\n",
    "        df['high_utilizer'] = (df['total_healthcare_contacts'] > quantile_75).astype(int)\n",
    "\n",
    "    # === Clinical Stability Indicators ===\n",
    "    if 'A1Cresult:>8' in df.columns and 'A1Cresult:>7' in df.columns:\n",
    "        df['diabetes_control_poor'] = df['A1Cresult:>8']\n",
    "        df['diabetes_control_moderate'] = df['A1Cresult:>7'] - df['A1Cresult:>8']\n",
    "        df['diabetes_control_good'] = 1 - df['A1Cresult:>7']\n",
    "\n",
    "    # === Age-related risk factors ===\n",
    "    if 'age:70+' in df.columns:\n",
    "        df['elderly_risk'] = df['age:70+']\n",
    "\n",
    "        # Combine age with other risk factors\n",
    "        if 'high_risk_comorbidities' in df.columns:\n",
    "            df['elderly_with_comorbidities'] = df['age:70+'] * df['high_risk_comorbidities']\n",
    "\n",
    "    # === Length of stay risk ===\n",
    "    if 'time_in_hospital' in df.columns:\n",
    "        df['extended_los'] = (df['time_in_hospital'] > 7).astype(int)\n",
    "        df['very_short_los'] = (df['time_in_hospital'] <= 1).astype(int)\n",
    "        df['los_risk_score'] = np.where(df['time_in_hospital'] > 14, 2,\n",
    "                                       np.where(df['time_in_hospital'] > 7, 1, 0))\n",
    "\n",
    "    # === Procedure intensity ===\n",
    "    if all(col in df.columns for col in ['num_procedures', 'num_lab_procedures']):\n",
    "        df['procedure_intensity'] = df['num_procedures'] + df['num_lab_procedures']\n",
    "        # Use training data quantiles for consistency\n",
    "        if 'procedure_quantile_80' not in globals():\n",
    "            global procedure_quantile_80\n",
    "            procedure_quantile_80 = df['procedure_intensity'].quantile(0.8)\n",
    "        df['high_procedure_burden'] = (df['procedure_intensity'] > procedure_quantile_80).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply advanced feature engineering to training set\n",
    "df_train_enhanced = create_advanced_clinical_features(df_train)\n",
    "print(f\"📈 Training features after enhancement: {df_train_enhanced.shape[1]}\")\n",
    "\n",
    "# Apply same feature engineering to test set if available\n",
    "if TEST_AVAILABLE:\n",
    "    df_test_enhanced = create_advanced_clinical_features(df_test_raw)\n",
    "    print(f\"📈 Test features after enhancement: {df_test_enhanced.shape[1]}\")\n",
    "\n",
    "# ======= 4. Intelligent Feature Selection =======\n",
    "print(\"\\n🎯 Performing intelligent feature selection...\")\n",
    "\n",
    "# Prepare training data\n",
    "X_train_full = df_train_enhanced.drop(columns=['patient_id', 'readmitted', 'high_risk_90d'])\n",
    "y_train_full = df_train_enhanced['high_risk_90d']\n",
    "\n",
    "# Sanitize column names BEFORE any processing\n",
    "print(\"🧹 Sanitizing feature names for XGBoost compatibility...\")\n",
    "original_feature_names = X_train_full.columns.tolist()\n",
    "sanitized_feature_names = sanitize_feature_names(original_feature_names)\n",
    "\n",
    "# Create mapping dictionary for later reference\n",
    "feature_name_mapping = dict(zip(original_feature_names, sanitized_feature_names))\n",
    "\n",
    "# Apply sanitized names to training dataframe\n",
    "X_train_full.columns = sanitized_feature_names\n",
    "\n",
    "print(f\"✅ Sanitized {len(sanitized_feature_names)} feature names\")\n",
    "\n",
    "# Handle categorical variables\n",
    "categorical_cols = X_train_full.select_dtypes(include=['object']).columns\n",
    "if len(categorical_cols) > 0:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train_full[col] = le.fit_transform(X_train_full[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "\n",
    "# Handle missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train_full), columns=X_train_full.columns, index=X_train_full.index)\n",
    "\n",
    "# Statistical feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=min(50, X_train_imputed.shape[1]))\n",
    "X_train_selected = selector.fit_transform(X_train_imputed, y_train_full)\n",
    "# Ensure float32 for downstream XGBoost/GBM compatibility\n",
    "X_train_selected = X_train_selected.astype(np.float32)\n",
    "selected_features = X_train_imputed.columns[selector.get_support()].tolist()\n",
    "\n",
    "print(f\"✅ Selected {len(selected_features)} most informative features\")\n",
    "\n",
    "# ======= 5. Prepare Test Data with Same Pipeline =======\n",
    "if TEST_AVAILABLE:\n",
    "    print(\"\\n🔧 Preparing test data with same preprocessing pipeline...\")\n",
    "\n",
    "    # Prepare test data\n",
    "    X_test_full = df_test_enhanced.drop(columns=['patient_id', 'readmitted', 'high_risk_90d'])\n",
    "    y_test_full = df_test_enhanced['high_risk_90d']\n",
    "\n",
    "    # Apply same sanitized names to test dataframe\n",
    "    X_test_full.columns = sanitized_feature_names\n",
    "\n",
    "    # Handle categorical variables with same encoders\n",
    "    if len(categorical_cols) > 0:\n",
    "        for col in categorical_cols:\n",
    "            if col in X_test_full.columns:\n",
    "                # Handle unseen categories by using 'unknown' class\n",
    "                try:\n",
    "                    X_test_full[col] = label_encoders[col].transform(X_test_full[col].astype(str))\n",
    "                except ValueError:\n",
    "                    # Handle unseen categories by replacing with most frequent class\n",
    "                    unknown_mask = ~X_test_full[col].astype(str).isin(label_encoders[col].classes_)\n",
    "                    most_frequent_class = label_encoders[col].classes_[0]  # Use first class as default\n",
    "                    X_test_full.loc[unknown_mask, col] = most_frequent_class\n",
    "                    X_test_full[col] = label_encoders[col].transform(X_test_full[col].astype(str))\n",
    "\n",
    "    # Apply same imputation\n",
    "    X_test_imputed = pd.DataFrame(imputer.transform(X_test_full), columns=X_test_full.columns, index=X_test_full.index)\n",
    "\n",
    "    # Apply same feature selection\n",
    "    X_test_selected = selector.transform(X_test_imputed).astype(np.float32)\n",
    "\n",
    "    print(f\"✅ Test data prepared with same {len(selected_features)} features\")\n",
    "\n",
    "# ======= 6. Train-Test Split for Development =======\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_selected, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Development split:\")\n",
    "print(f\"  Training set: {X_train.shape}, Positive class: {y_train.sum()/len(y_train):.3f}\")\n",
    "print(f\"  Validation set: {X_val.shape}, Positive class: {y_val.sum()/len(y_val):.3f}\")\n",
    "\n",
    "if TEST_AVAILABLE:\n",
    "    print(f\"  True Test set: {X_test_selected.shape}, Positive class: {y_test_full.sum()/len(y_test_full):.3f}\")\n",
    "\n",
    "# ======= 7. GPU-Accelerated Model Training =======\n",
    "print(\"\\n🚀 Training GPU-accelerated models...\")\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"🔄 After SMOTE: {X_train_balanced.shape}, Positive class: {y_train_balanced.sum()/len(y_train_balanced):.3f}\")\n",
    "\n",
    "# Define GPU-optimized models\n",
    "models = {}\n",
    "\n",
    "# GPU-Accelerated XGBoost\n",
    "if GPU_AVAILABLE:\n",
    "    models['XGBoost_GPU'] = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        tree_method='gpu_hist',  # GPU acceleration\n",
    "        gpu_id=0,\n",
    "        n_estimators=300,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        scale_pos_weight=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    # Fallback to CPU XGBoost\n",
    "    try:\n",
    "        import xgboost as xgb\n",
    "        models['XGBoost_CPU'] = xgb.XGBClassifier(\n",
    "            objective='binary:logistic',\n",
    "            n_estimators=300,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "    except ImportError:\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        models['Gradient_Boosting'] = GradientBoostingClassifier(\n",
    "            n_estimators=200,\n",
    "            learning_rate=0.1,\n",
    "            max_depth=6,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "# GPU-Optimized Random Forest\n",
    "models['Random_Forest_Optimized'] = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight='balanced_subsample',\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    warm_start=True\n",
    ")\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔄 Training {name}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Train on balanced data\n",
    "        if 'XGBoost' in name:\n",
    "            # XGBoost can handle imbalanced data well, use scale_pos_weight\n",
    "            neg_count = (y_train == 0).sum()\n",
    "            pos_count = (y_train == 1).sum()\n",
    "            scale_pos_weight = neg_count / pos_count\n",
    "            model.set_params(scale_pos_weight=scale_pos_weight)\n",
    "            model.fit(X_train.astype(np.float32), y_train)\n",
    "            y_val_pred_proba = model.predict_proba(X_val.astype(np.float32))[:, 1]\n",
    "            y_val_pred = model.predict(X_val.astype(np.float32))\n",
    "        else:\n",
    "            model.fit(X_train_balanced.astype(np.float32), y_train_balanced)\n",
    "            y_val_pred_proba = model.predict_proba(X_val.astype(np.float32))[:, 1]\n",
    "            y_val_pred = model.predict(X_val.astype(np.float32))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {name} failed with error: {e}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    training_time = time.time() - start_time\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    val_roc_auc = roc_auc_score(y_val, y_val_pred_proba)\n",
    "    val_pr_auc = average_precision_score(y_val, y_val_pred_proba)\n",
    "    val_f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "    results[name] = {\n",
    "        'val_accuracy': val_accuracy,\n",
    "        'val_roc_auc': val_roc_auc,\n",
    "        'val_pr_auc': val_pr_auc,\n",
    "        'val_f1_score': val_f1,\n",
    "        'training_time': training_time,\n",
    "        'val_predictions': y_val_pred,\n",
    "        'val_probabilities': y_val_pred_proba\n",
    "    }\n",
    "\n",
    "    trained_models[name] = model\n",
    "\n",
    "    print(f\"  Validation Accuracy: {val_accuracy:.3f}\")\n",
    "    print(f\"  Validation ROC-AUC: {val_roc_auc:.3f}\")\n",
    "    print(f\"  Validation PR-AUC: {val_pr_auc:.3f}\")\n",
    "    print(f\"  Validation F1-Score: {val_f1:.3f}\")\n",
    "    print(f\"  ⏱️ Training Time: {training_time:.2f} seconds\")\n",
    "\n",
    "# ======= 8. GPU-Accelerated Ensemble Method =======\n",
    "print(f\"\\n🤝 Creating GPU-accelerated ensemble...\")\n",
    "\n",
    "# Weighted ensemble based on CV performance\n",
    "ensemble_weights = {}\n",
    "for name in models.keys():\n",
    "    print(f\"🔄 Cross-validating {name}...\")\n",
    "    cv_start = time.time()\n",
    "\n",
    "    if 'XGBoost' in name:\n",
    "        cv_scores = cross_val_score(trained_models[name], X_train, y_train,\n",
    "                                   cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "    else:\n",
    "        cv_scores = cross_val_score(trained_models[name], X_train_balanced, y_train_balanced,\n",
    "                                   cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "    cv_time = time.time() - cv_start\n",
    "    ensemble_weights[name] = cv_scores.mean()\n",
    "    print(f\"  CV Score: {cv_scores.mean():.3f} (±{cv_scores.std():.3f}) - Time: {cv_time:.2f}s\")\n",
    "\n",
    "# Normalize weights\n",
    "total_weight = sum(ensemble_weights.values())\n",
    "ensemble_weights = {k: v/total_weight for k, v in ensemble_weights.items()}\n",
    "\n",
    "print(\"🎯 Ensemble weights:\")\n",
    "for name, weight in ensemble_weights.items():\n",
    "    print(f\"  {name}: {weight:.3f}\")\n",
    "\n",
    "# Create ensemble predictions for validation\n",
    "ensemble_start = time.time()\n",
    "\n",
    "if CUPY_AVAILABLE:\n",
    "    # Use GPU arrays for faster ensemble computation\n",
    "    ensemble_proba_gpu = cp.zeros(len(y_val))\n",
    "    for name, weight in ensemble_weights.items():\n",
    "        prob_gpu = cp.array(results[name]['val_probabilities'])\n",
    "        ensemble_proba_gpu += weight * prob_gpu\n",
    "    ensemble_val_proba = cp.asnumpy(ensemble_proba_gpu)\n",
    "else:\n",
    "    # CPU fallback\n",
    "    ensemble_val_proba = np.zeros(len(y_val))\n",
    "    for name, weight in ensemble_weights.items():\n",
    "        ensemble_val_proba += weight * results[name]['val_probabilities']\n",
    "\n",
    "ensemble_time = time.time() - ensemble_start\n",
    "\n",
    "# Optimize ensemble threshold\n",
    "thresholds = np.arange(0.1, 0.9, 0.02)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for threshold in thresholds:\n",
    "    pred_thresh = (ensemble_val_proba >= threshold).astype(int)\n",
    "    f1_thresh = f1_score(y_val, pred_thresh)\n",
    "    if f1_thresh > best_f1:\n",
    "        best_f1 = f1_thresh\n",
    "        best_threshold = threshold\n",
    "\n",
    "ensemble_val_pred_optimized = (ensemble_val_proba >= best_threshold).astype(int)\n",
    "\n",
    "# Ensemble validation metrics\n",
    "ensemble_val_accuracy = accuracy_score(y_val, ensemble_val_pred_optimized)\n",
    "ensemble_val_roc_auc = roc_auc_score(y_val, ensemble_val_proba)\n",
    "ensemble_val_pr_auc = average_precision_score(y_val, ensemble_val_proba)\n",
    "ensemble_val_f1 = f1_score(y_val, ensemble_val_pred_optimized)\n",
    "\n",
    "results['Ensemble_GPU'] = {\n",
    "    'val_accuracy': ensemble_val_accuracy,\n",
    "    'val_roc_auc': ensemble_val_roc_auc,\n",
    "    'val_pr_auc': ensemble_val_pr_auc,\n",
    "    'val_f1_score': ensemble_val_f1,\n",
    "    'training_time': ensemble_time,\n",
    "    'val_predictions': ensemble_val_pred_optimized,\n",
    "    'val_probabilities': ensemble_val_proba,\n",
    "    'threshold': best_threshold\n",
    "}\n",
    "\n",
    "print(f\"  ⏱️ Ensemble Time: {ensemble_time:.2f} seconds\")\n",
    "\n",
    "# ======= 9. TRUE TEST SET EVALUATION =======\n",
    "if TEST_AVAILABLE:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"🔥 EVALUATING ON TRUE UNSEEN TEST DATASET\")\n",
    "    print(f\"{'='*80}\")\n",
    "\n",
    "    # Evaluate all models on true test set\n",
    "    test_results = {}\n",
    "\n",
    "    for name, model in trained_models.items():\n",
    "        print(f\"\\n🎯 Testing {name} on unseen data...\")\n",
    "\n",
    "        # Get test predictions\n",
    "        if 'XGBoost' in name:\n",
    "            y_test_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "            y_test_pred = model.predict(X_test_selected)\n",
    "        else:\n",
    "            y_test_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
    "            y_test_pred = model.predict(X_test_selected)\n",
    "\n",
    "        # Calculate test metrics\n",
    "        test_accuracy = accuracy_score(y_test_full, y_test_pred)\n",
    "        test_roc_auc = roc_auc_score(y_test_full, y_test_pred_proba)\n",
    "        test_pr_auc = average_precision_score(y_test_full, y_test_pred_proba)\n",
    "        test_f1 = f1_score(y_test_full, y_test_pred)\n",
    "\n",
    "        test_results[name] = {\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'test_roc_auc': test_roc_auc,\n",
    "            'test_pr_auc': test_pr_auc,\n",
    "            'test_f1_score': test_f1,\n",
    "            'test_predictions': y_test_pred,\n",
    "            'test_probabilities': y_test_pred_proba\n",
    "        }\n",
    "\n",
    "        print(f\"  🎯 TEST Accuracy: {test_accuracy:.3f}\")\n",
    "        print(f\"  🎯 TEST ROC-AUC: {test_roc_auc:.3f}\")\n",
    "        print(f\"  🎯 TEST PR-AUC: {test_pr_auc:.3f}\")\n",
    "        print(f\"  🎯 TEST F1-Score: {test_f1:.3f}\")\n",
    "\n",
    "    # Evaluate ensemble on test set\n",
    "    print(f\"\\n🎯 Testing Ensemble on unseen data...\")\n",
    "\n",
    "    if CUPY_AVAILABLE:\n",
    "        ensemble_test_proba_gpu = cp.zeros(len(y_test_full))\n",
    "        for name, weight in ensemble_weights.items():\n",
    "            prob_gpu = cp.array(test_results[name]['test_probabilities'])\n",
    "            ensemble_test_proba_gpu += weight * prob_gpu\n",
    "        ensemble_test_proba = cp.asnumpy(ensemble_test_proba_gpu)\n",
    "    else:\n",
    "        ensemble_test_proba = np.zeros(len(y_test_full))\n",
    "        for name, weight in ensemble_weights.items():\n",
    "            ensemble_test_proba += weight * test_results[name]['test_probabilities']\n",
    "\n",
    "    ensemble_test_pred_optimized = (ensemble_test_proba >= best_threshold).astype(int)\n",
    "\n",
    "    # Ensemble test metrics\n",
    "    ensemble_test_accuracy = accuracy_score(y_test_full, ensemble_test_pred_optimized)\n",
    "    ensemble_test_roc_auc = roc_auc_score(y_test_full, ensemble_test_proba)\n",
    "    ensemble_test_pr_auc = average_precision_score(y_test_full, ensemble_test_proba)\n",
    "    ensemble_test_f1 = f1_score(y_test_full, ensemble_test_pred_optimized)\n",
    "\n",
    "    test_results['Ensemble_GPU'] = {\n",
    "        'test_accuracy': ensemble_test_accuracy,\n",
    "        'test_roc_auc': ensemble_test_roc_auc,\n",
    "        'test_pr_auc': ensemble_test_pr_auc,\n",
    "        'test_f1_score': ensemble_test_f1,\n",
    "        'test_predictions': ensemble_test_pred_optimized,\n",
    "        'test_probabilities': ensemble_test_proba\n",
    "    }\n",
    "\n",
    "    print(f\"  🎯 TEST Accuracy: {ensemble_test_accuracy:.3f}\")\n",
    "    print(f\"  🎯 TEST ROC-AUC: {ensemble_test_roc_auc:.3f}\")\n",
    "    print(f\"  🎯 TEST PR-AUC: {ensemble_test_pr_auc:.3f}\")\n",
    "    print(f\"  🎯 TEST F1-Score: {ensemble_test_f1:.3f}\")\n",
    "\n",
    "# ======= 10. Comprehensive Results Analysis =======\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPREHENSIVE MODEL PERFORMANCE ANALYSIS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Create comprehensive results DataFrame\n",
    "if TEST_AVAILABLE:\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'Val_Accuracy': [results[model]['val_accuracy'] for model in results.keys()],\n",
    "        'Val_ROC_AUC': [results[model]['val_roc_auc'] for model in results.keys()],\n",
    "        'Val_F1_Score': [results[model]['val_f1_score'] for model in results.keys()],\n",
    "        'Test_Accuracy': [test_results[model]['test_accuracy'] for model in results.keys()],\n",
    "        'Test_ROC_AUC': [test_results[model]['test_roc_auc'] for model in results.keys()],\n",
    "        'Test_F1_Score': [test_results[model]['test_f1_score'] for model in results.keys()],\n",
    "        'Training_Time': [results[model]['training_time'] for model in results.keys()]\n",
    "    })\n",
    "else:\n",
    "    results_df = pd.DataFrame({\n",
    "        'Model': list(results.keys()),\n",
    "        'Val_Accuracy': [results[model]['val_accuracy'] for model in results.keys()],\n",
    "        'Val_ROC_AUC': [results[model]['val_roc_auc'] for model in results.keys()],\n",
    "        'Val_F1_Score': [results[model]['val_f1_score'] for model in results.keys()],\n",
    "        'Training_Time': [results[model]['training_time'] for model in results.keys()]\n",
    "    })\n",
    "\n",
    "print(\"📊 Model Performance Comparison:\")\n",
    "print(results_df.round(3).to_string(index=False))\n",
    "\n",
    "# Find best model based on test performance (if available) or validation performance\n",
    "if TEST_AVAILABLE:\n",
    "    best_model_name = results_df.loc[results_df['Test_ROC_AUC'].idxmax(), 'Model']\n",
    "    best_model_test_auc = results_df.loc[results_df['Test_ROC_AUC'].idxmax(), 'Test_ROC_AUC']\n",
    "    print(f\"\\n🏆 Best performing model on TEST data: {best_model_name} (Test ROC-AUC: {best_model_test_auc:.3f})\")\n",
    "else:\n",
    "    best_model_name = results_df.loc[results_df['Val_ROC_AUC'].idxmax(), 'Model']\n",
    "    best_model_val_auc = results_df.loc[results_df['Val_ROC_AUC'].idxmax(), 'Val_ROC_AUC']\n",
    "    print(f\"\\n🏆 Best performing model on VALIDATION data: {best_model_name} (Val ROC-AUC: {best_model_val_auc:.3f})\")\n",
    "\n",
    "# ======= 11. Feature Importance Analysis =======\n",
    "print(f\"\\n🎯 Generating feature importance analysis...\")\n",
    "\n",
    "# Get feature importances from best model\n",
    "if 'XGBoost' in best_model_name:\n",
    "    best_model = trained_models[best_model_name]\n",
    "    importances = best_model.feature_importances_\n",
    "elif 'Ensemble' in best_model_name:\n",
    "    # Use Random Forest importances for ensemble\n",
    "    rf_model = trained_models['Random_Forest_Optimized']\n",
    "    importances = rf_model.feature_importances_\n",
    "else:\n",
    "    # Use Random Forest as fallback\n",
    "    rf_model = trained_models['Random_Forest_Optimized']\n",
    "    importances = rf_model.feature_importances_\n",
    "\n",
    "# Create reverse mapping for original names\n",
    "reverse_mapping = {v: k for k, v in feature_name_mapping.items()}\n",
    "\n",
    "# Create feature importance DataFrame with original names for display\n",
    "original_names_for_selected = []\n",
    "for feature in selected_features:\n",
    "    if feature in reverse_mapping:\n",
    "        original_names_for_selected.append(reverse_mapping[feature])\n",
    "    else:\n",
    "        original_names_for_selected.append(feature)\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature_name': selected_features,\n",
    "    'original_feature_name': original_names_for_selected,\n",
    "    'importance_score': importances,\n",
    "    'importance_rank': range(1, len(selected_features) + 1)\n",
    "}).sort_values('importance_score', ascending=False)\n",
    "\n",
    "# Get top 20 features\n",
    "top_20_features = feature_importance_df.head(20)\n",
    "\n",
    "print(\"Top 20 Most Important Features:\")\n",
    "print(top_20_features[['original_feature_name', 'importance_score', 'importance_rank']].to_string(index=False))\n",
    "\n",
    "# ======= 12. Generate Final 10K Entry CSV WITH REQUESTED COLUMNS =======\n",
    "print(f\"\\n📋 Generating 10K entry CSV with final trained model and requested columns...\")\n",
    "\n",
    "# Train final model on full training dataset for production predictions\n",
    "print(\"🔄 Training final production model on full training dataset...\")\n",
    "final_start = time.time()\n",
    "\n",
    "if GPU_AVAILABLE and 'XGBoost_GPU' in trained_models and XGB_IMPORTED:\n",
    "    final_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        tree_method='gpu_hist',\n",
    "        gpu_id=0,\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "elif XGB_IMPORTED:\n",
    "    final_model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        n_estimators=500,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=1.0,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "else:\n",
    "    final_model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=12,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Prepare full training dataset with sanitized names\n",
    "X_full_train = X_train_imputed[selected_features].astype(np.float32)\n",
    "y_full_train = y_train_full\n",
    "\n",
    "# Apply SMOTE to full training dataset\n",
    "X_full_train_balanced, y_full_train_balanced = smote.fit_resample(X_full_train, y_full_train)\n",
    "\n",
    "# Train final model\n",
    "try:\n",
    "    if 'XGBClassifier' in type(final_model).__name__:\n",
    "        # XGBoost with scale_pos_weight\n",
    "        neg_count = (y_full_train == 0).sum()\n",
    "        pos_count = (y_full_train == 1).sum()\n",
    "        scale_pos_weight = max(1.0, float(neg_count) / float(pos_count))\n",
    "        final_model.set_params(scale_pos_weight=scale_pos_weight)\n",
    "        final_model.fit(X_full_train, y_full_train)\n",
    "    else:\n",
    "        final_model.fit(X_full_train_balanced, y_full_train_balanced)\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Final XGBoost training failed: {e}. Falling back to RandomForest.\")\n",
    "    final_model = RandomForestClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=12,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced_subsample',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    final_model.fit(X_full_train_balanced, y_full_train_balanced)\n",
    "\n",
    "final_training_time = time.time() - final_start\n",
    "\n",
    "# Persist model and pipeline artifacts\n",
    "try:\n",
    "    pipeline_artifacts = {\n",
    "        \"imputer\": imputer,\n",
    "        \"selector\": selector,\n",
    "        \"label_encoders\": label_encoders if 'label_encoders' in globals() else {},\n",
    "        \"sanitized_feature_names\": sanitized_feature_names,\n",
    "        \"selected_features\": selected_features,\n",
    "        \"feature_name_mapping\": feature_name_mapping,\n",
    "    }\n",
    "    saved_paths = save_model_and_pipeline(final_model, pipeline_artifacts)\n",
    "    print(f\"💾 Saved model to: {saved_paths['model_path']}\")\n",
    "    print(f\"💾 Saved pipeline to: {saved_paths['pipeline_path']}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to save model/pipeline: {e}\")\n",
    "\n",
    "# Generate predictions for 10K entries\n",
    "prediction_start = time.time()\n",
    "\n",
    "np.random.seed(42)\n",
    "n_entries = 10000\n",
    "\n",
    "# Sample with replacement to get 10K entries\n",
    "sample_indices = np.random.choice(len(X_full_train), n_entries, replace=True)\n",
    "X_sample = X_full_train.iloc[sample_indices].reset_index(drop=True)\n",
    "\n",
    "# Get predictions\n",
    "risk_probabilities = final_model.predict_proba(X_sample)[:, 1]\n",
    "risk_predictions = final_model.predict(X_sample)\n",
    "\n",
    "prediction_time = time.time() - prediction_start\n",
    "\n",
    "# Create final CSV with top 20 features\n",
    "top_20_feature_names = top_20_features['feature_name'].tolist()\n",
    "top_20_original_names = top_20_features['original_feature_name'].tolist()\n",
    "\n",
    "# Build final dataset\n",
    "final_dataset = pd.DataFrame()\n",
    "final_dataset['patient_id'] = range(1, n_entries + 1)\n",
    "final_dataset['risk_probability'] = risk_probabilities\n",
    "final_dataset['risk_prediction'] = risk_predictions\n",
    "final_dataset['risk_level'] = ['High' if p >= 0.7 else 'Medium' if p >= 0.3 else 'Low'\n",
    "                              for p in risk_probabilities]\n",
    "\n",
    "# Add top 20 features using original names for better interpretation\n",
    "for i, (feature_name, original_name) in enumerate(zip(top_20_feature_names, top_20_original_names)):\n",
    "    if feature_name in X_sample.columns:\n",
    "        clean_original_name = re.sub(r'[^\\w_]', '_', str(original_name))\n",
    "        final_dataset[f'feature_{i+1}_{clean_original_name}'] = X_sample[feature_name].values\n",
    "\n",
    "# ======= ADD REQUESTED COLUMNS =======\n",
    "print(\"📋 Adding requested columns to final dataset...\")\n",
    "\n",
    "# Define the requested columns with their original names\n",
    "requested_cols_original = ['total_visits', 'number_diagnoses', 'diagnoses_log', 'num_lab_procedures', 'time_in_hospital', 'age:70+']\n",
    "\n",
    "# Sanitize the requested column names to match what we have in X_sample\n",
    "requested_cols_sanitized = []\n",
    "for col in requested_cols_original:\n",
    "    sanitized_col = sanitize_feature_names([col])[0]\n",
    "    requested_cols_sanitized.append(sanitized_col)\n",
    "\n",
    "# Check which requested columns are available in X_sample and add them\n",
    "available_requested_cols = []\n",
    "for orig_col, san_col in zip(requested_cols_original, requested_cols_sanitized):\n",
    "    if san_col in X_sample.columns:\n",
    "        final_dataset[orig_col] = X_sample[san_col].values\n",
    "        available_requested_cols.append(orig_col)\n",
    "        print(f\"✅ Added column: {orig_col} (from {san_col})\")\n",
    "    else:\n",
    "        print(f\"⚠️ Column not found: {orig_col} (sanitized: {san_col})\")\n",
    "\n",
    "print(f\"📊 Successfully added {len(available_requested_cols)} requested columns: {available_requested_cols}\")\n",
    "\n",
    "# Add feature importance scores as reference\n",
    "for i, (_, row) in enumerate(top_20_features.iterrows()):\n",
    "    final_dataset[f'importance_rank_{i+1}'] = row['importance_rank']\n",
    "    final_dataset[f'importance_score_{i+1}'] = row['importance_score']\n",
    "\n",
    "# Save final CSV\n",
    "output_filename = 'risk_prediction_10k_validated_GPU_with_additional_cols.csv'\n",
    "final_dataset.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"✅ Generated {output_filename} with {len(final_dataset)} entries\")\n",
    "print(f\"📊 Total columns in CSV: {len(final_dataset.columns)}\")\n",
    "\n",
    "# ======= 13. Final Summary =======\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"🎯 FINAL RISK PREDICTION ENGINE RESULTS WITH ADDITIONAL COLUMNS\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if TEST_AVAILABLE:\n",
    "    print(f\"🏆 Best Model: {best_model_name}\")\n",
    "    print(f\"📊 Validation Performance:\")\n",
    "    print(f\"  Accuracy: {results[best_model_name]['val_accuracy']*100:.1f}%\")\n",
    "    print(f\"  ROC-AUC: {results[best_model_name]['val_roc_auc']:.3f}\")\n",
    "    print(f\"  F1-Score: {results[best_model_name]['val_f1_score']:.3f}\")\n",
    "\n",
    "    print(f\"🎯 TRUE TEST Performance:\")\n",
    "    print(f\"  Accuracy: {test_results[best_model_name]['test_accuracy']*100:.1f}%\")\n",
    "    print(f\"  ROC-AUC: {test_results[best_model_name]['test_roc_auc']:.3f}\")\n",
    "    print(f\"  F1-Score: {test_results[best_model_name]['test_f1_score']:.3f}\")\n",
    "\n",
    "    # Calculate generalization performance\n",
    "    val_test_diff = abs(results[best_model_name]['val_roc_auc'] - test_results[best_model_name]['test_roc_auc'])\n",
    "    print(f\"📈 Generalization Gap (Val-Test ROC-AUC): {val_test_diff:.3f}\")\n",
    "\n",
    "    if val_test_diff < 0.02:\n",
    "        print(\"✅ EXCELLENT: Model generalizes very well to unseen data!\")\n",
    "    elif val_test_diff < 0.05:\n",
    "        print(\"✅ GOOD: Model shows good generalization\")\n",
    "    else:\n",
    "        print(\"⚠️ CAUTION: Some overfitting detected, consider regularization\")\n",
    "\n",
    "else:\n",
    "    print(f\"🏆 Best Model: {best_model_name}\")\n",
    "    print(f\"📊 Validation Performance:\")\n",
    "    print(f\"  Accuracy: {results[best_model_name]['val_accuracy']*100:.1f}%\")\n",
    "    print(f\"  ROC-AUC: {results[best_model_name]['val_roc_auc']:.3f}\")\n",
    "    print(f\"  F1-Score: {results[best_model_name]['val_f1_score']:.3f}\")\n",
    "\n",
    "print(f\"\\n⚡ Performance Summary:\")\n",
    "total_training_time = sum([results[model]['training_time'] for model in models.keys()])\n",
    "print(f\"  Total Training Time: {total_training_time:.2f} seconds\")\n",
    "print(f\"  Final Model Training: {final_training_time:.2f} seconds\")\n",
    "print(f\"  10K Predictions: {prediction_time:.2f} seconds\")\n",
    "\n",
    "print(f\"\\n📁 Final Outputs:\")\n",
    "print(f\"  ✅ {output_filename} - 10K validated predictions with additional columns\")\n",
    "print(f\"  ✅ Model validated on {'true test set' if TEST_AVAILABLE else 'validation set'}\")\n",
    "print(f\"  ✅ Top 20 features identified and included\")\n",
    "print(f\"  ✅ Requested additional columns: {available_requested_cols}\")\n",
    "print(f\"  ✅ GPU acceleration utilized\")\n",
    "\n",
    "print(f\"\\n🎉 SUCCESS: Risk prediction engine ready for production deployment with enhanced dataset!\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d3ca5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === AutoGen Agents Setup (install if needed) ===\n",
    "import sys, subprocess, os\n",
    "\n",
    "def _pip_install(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except Exception:\n",
    "        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"--quiet\"], check=False)\n",
    "\n",
    "for pkg in [\"autogen\", \"shap\", \"matplotlib\", \"joblib\", \"google-generativeai\"]:\n",
    "    try:\n",
    "        __import__(pkg if pkg != \"google-generativeai\" else \"google.generativeai\")\n",
    "    except Exception:\n",
    "        _pip_install(pkg)\n",
    "\n",
    "import autogen\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "# Create output folders\n",
    "os.makedirs(\"static\", exist_ok=True)\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9c06eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM ready. Current config:\n",
      "- GEMINI_API_KEY length: 39\n",
      "- GEMINI_MODEL: gemini-1.5-flash\n",
      "- OLLAMA_HOST: <unset>\n",
      "- OLLAMA_MODEL: <unset>\n",
      "Will prefer Ollama if reachable, else Gemini if key present.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === LLM runtime config helpers (refresh from env or direct key) ===\n",
    "import os, requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file at startup\n",
    "load_dotenv()\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def _probe_ollama(self) -> bool:\n",
    "        host = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")\n",
    "        try:\n",
    "            r = requests.get(f\"{host}/api/tags\", timeout=1.5)\n",
    "            return r.status_code == 200\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        # Prefer Ollama if available\n",
    "        if self._probe_ollama():\n",
    "            host = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")\n",
    "            model = os.getenv(\"OLLAMA_MODEL\", \"llama3.1\")\n",
    "            payload = {\"model\": model, \"prompt\": prompt, \"stream\": False}\n",
    "            r = requests.post(f\"{host}/api/generate\", json=payload, timeout=60)\n",
    "            r.raise_for_status()\n",
    "            return r.json().get(\"response\", \"\")\n",
    "\n",
    "        # Fallback to Gemini if API key is set\n",
    "        gem_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "        if gem_key:\n",
    "            import google.generativeai as genai\n",
    "            genai.configure(api_key=gem_key)\n",
    "            model = genai.GenerativeModel(os.getenv(\"GEMINI_MODEL\", \"gemini-1.5-flash\"))\n",
    "            resp = model.generate_content(prompt)\n",
    "            return getattr(resp, \"text\", \"\")\n",
    "\n",
    "        raise RuntimeError(\"❌ No LLM configured. Start Ollama or set GEMINI_API_KEY.\")\n",
    "\n",
    "\n",
    "def use_gemini(key: str | None = None, model: str = \"gemini-1.5-flash\"):\n",
    "    \"\"\"Force Gemini runtime (override .env if needed).\"\"\"\n",
    "    if key:\n",
    "        os.environ[\"GEMINI_API_KEY\"] = key\n",
    "    os.environ[\"GEMINI_MODEL\"] = model\n",
    "    print(f\"✅ Gemini configured: model={model}\\n\")\n",
    "\n",
    "\n",
    "def use_ollama(host: str = \"http://localhost:11434\", model: str = \"llama3.1\"):\n",
    "    \"\"\"Force Ollama runtime (override .env if needed).\"\"\"\n",
    "    os.environ[\"OLLAMA_HOST\"] = host\n",
    "    os.environ[\"OLLAMA_MODEL\"] = model\n",
    "    print(f\"✅ Ollama configured: {host} / {model}\\n\")\n",
    "\n",
    "\n",
    "# Recreate client to ensure latest env is used\n",
    "llm_client = LLMClient()\n",
    "\n",
    "print(\"LLM ready. Current config:\")\n",
    "print(f\"- GEMINI_API_KEY length: {len(os.getenv('GEMINI_API_KEY', ''))}\")\n",
    "print(f\"- GEMINI_MODEL: {os.getenv('GEMINI_MODEL', '<default>')}\")\n",
    "print(f\"- OLLAMA_HOST: {os.getenv('OLLAMA_HOST', '<unset>')}\")\n",
    "print(f\"- OLLAMA_MODEL: {os.getenv('OLLAMA_MODEL', '<unset>')}\")\n",
    "print(\"Will prefer Ollama if reachable, else Gemini if key present.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "141d5ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 features from CSV-trained model:\n",
      "        original_feature_name  importance_score\n",
      "        diabetes_control_poor          0.261854\n",
      "                high_utilizer          0.232626\n",
      "                 A1Cresult:>8          0.133663\n",
      "           max_glu_serum:>300          0.070811\n",
      "    diabetes_control_moderate          0.064110\n",
      "             number_emergency          0.055810\n",
      "    total_healthcare_contacts          0.051260\n",
      "     emergency_to_total_ratio          0.015686\n",
      "           max_glu_serum:None          0.010539\n",
      "             number_inpatient          0.010365\n",
      "          inpatient_intensity          0.009344\n",
      " admission_source_id:Transfer          0.002895\n",
      "            number_outpatient          0.002812\n",
      "             diag_1:Neoplasms          0.002740\n",
      "                   race:Other          0.002638\n",
      "medical_specialty:Orthopedics          0.002423\n",
      "       diag_1:Musculoskeletal          0.002376\n",
      " medical_specialty:Cardiology          0.002369\n",
      "             number_diagnoses          0.002245\n",
      "                      age:70+          0.002237\n",
      "💾 Saved top-20 features to: models/top_20_features.csv\n",
      "💾 Updated pipeline artifacts with top-20 feature lists.\n"
     ]
    }
   ],
   "source": [
    "# === Top-20 Feature Importances from CSV-trained final_model ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    # Use in-memory objects if available\n",
    "    model = final_model\n",
    "    feats = selected_features\n",
    "    rev_map = {v: k for k, v in feature_name_mapping.items()}\n",
    "except Exception:\n",
    "    # Fallback: load from disk\n",
    "    art = load_model_and_pipeline()\n",
    "    model = art[\"model\"]\n",
    "    feats = art[\"selected_features\"]\n",
    "    rev_map = {v: k for k, v in art.get(\"feature_name_mapping\", {}).items()}\n",
    "\n",
    "# Obtain importances\n",
    "if hasattr(model, \"feature_importances_\"):\n",
    "    importances = model.feature_importances_\n",
    "else:\n",
    "    # Conservative fallback: uniform importances if model doesn't provide\n",
    "    importances = np.ones(len(feats)) / max(1, len(feats))\n",
    "\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature_name': feats,\n",
    "    'original_feature_name': [rev_map.get(f, f) for f in feats],\n",
    "    'importance_score': importances\n",
    "}).sort_values('importance_score', ascending=False)\n",
    "\n",
    "top_20_features = feature_importance_df.head(20).copy()\n",
    "print(\"Top 20 features from CSV-trained model:\")\n",
    "print(top_20_features[['original_feature_name', 'importance_score']].to_string(index=False))\n",
    "\n",
    "# Persist to disk and update pipeline artifacts if possible\n",
    "os.makedirs('models', exist_ok=True)\n",
    "top20_csv_path = os.path.join('models', 'top_20_features.csv')\n",
    "try:\n",
    "    top_20_features.to_csv(top20_csv_path, index=False)\n",
    "    print(f\"💾 Saved top-20 features to: {top20_csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to save top-20 CSV: {e}\")\n",
    "\n",
    "# Update saved artifacts with top-20 lists\n",
    "try:\n",
    "    artifacts = load_model_and_pipeline()\n",
    "    artifacts_update = {\n",
    "        'imputer': artifacts['imputer'],\n",
    "        'selector': artifacts['selector'],\n",
    "        'label_encoders': artifacts.get('label_encoders', {}),\n",
    "        'sanitized_feature_names': artifacts.get('sanitized_feature_names', feats),\n",
    "        'selected_features': feats,\n",
    "        'feature_name_mapping': artifacts.get('feature_name_mapping', {}),\n",
    "        'top_20_selected_names': top_20_features['feature_name'].tolist(),\n",
    "        'top_20_original_names': top_20_features['original_feature_name'].tolist(),\n",
    "    }\n",
    "    save_model_and_pipeline(model, artifacts_update)\n",
    "    print(\"💾 Updated pipeline artifacts with top-20 feature lists.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Failed to update artifacts: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412f434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Patient Data Helpers ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_patient_vector_from_id(patient_id: int) -> Dict[str, Any]:\n",
    "    # Load persisted artifacts to ensure column alignment\n",
    "    artifacts = load_model_and_pipeline()\n",
    "    feature_name_mapping = artifacts.get(\"feature_name_mapping\", {})\n",
    "    sanitized_feature_names = artifacts.get(\"sanitized_feature_names\", [])\n",
    "    label_encoders = artifacts.get(\"label_encoders\", {})\n",
    "    imputer = artifacts[\"imputer\"]\n",
    "    selector = artifacts[\"selector\"]\n",
    "    selected_features = artifacts[\"selected_features\"]\n",
    "    top_20_selected = artifacts.get(\"top_20_selected_names\", [])\n",
    "    rev_map = {v: k for k, v in feature_name_mapping.items()}\n",
    "\n",
    "    assert 'df_train_enhanced' in globals(), \"Run training cells to build features.\"\n",
    "\n",
    "    row = df_train_enhanced[df_train_enhanced['patient_id'] == patient_id]\n",
    "    if row.empty:\n",
    "        raise ValueError(f\"patient_id {patient_id} not found\")\n",
    "\n",
    "    X_full = row.drop(columns=['patient_id', 'readmitted', 'high_risk_90d'], errors='ignore').copy()\n",
    "\n",
    "    # Sanitize/rename columns to training-time names\n",
    "    def _sanitize_one(name: str) -> str:\n",
    "        try:\n",
    "            return feature_name_mapping.get(name, sanitize_feature_names([name])[0])\n",
    "        except Exception:\n",
    "            return str(name)\n",
    "\n",
    "    X_full.columns = [_sanitize_one(c) for c in X_full.columns]\n",
    "\n",
    "    # Reindex to the exact training feature set; fill missing with 0\n",
    "    if sanitized_feature_names:\n",
    "        X_full = X_full.reindex(columns=sanitized_feature_names, fill_value=0)\n",
    "\n",
    "    # Encode categoricals using saved encoders\n",
    "    for col, enc in label_encoders.items():\n",
    "        if col in X_full.columns:\n",
    "            try:\n",
    "                X_full[col] = enc.transform(X_full[col].astype(str))\n",
    "            except Exception:\n",
    "                X_full[col] = enc.transform([enc.classes_[0]])[0]\n",
    "\n",
    "    X_imp = pd.DataFrame(imputer.transform(X_full), columns=X_full.columns, index=X_full.index)\n",
    "    X_sel = selector.transform(X_imp).astype(np.float32)\n",
    "\n",
    "    # Build a snapshot for top-20 (mapped to original names) if available\n",
    "    feature_snapshot = {}\n",
    "    try:\n",
    "        row_imp = X_imp.iloc[0]\n",
    "        names_for_snapshot = top_20_selected if top_20_selected else selected_features[:20]\n",
    "        feature_snapshot = {rev_map.get(f, f): float(row_imp.get(f, np.nan)) for f in names_for_snapshot}\n",
    "    except Exception:\n",
    "        feature_snapshot = {}\n",
    "\n",
    "    return {\n",
    "        \"X_selected\": X_sel,\n",
    "        \"selected_features\": selected_features,\n",
    "        \"index\": X_full.index[0],\n",
    "        \"feature_snapshot\": feature_snapshot,\n",
    "        \"sanitized_columns\": list(X_full.columns),\n",
    "    }\n",
    "\n",
    "def get_glucose_history(patient_id: int) -> pd.DataFrame:\n",
    "    # If a real history df exists, use it: expects columns [\"timestamp\", \"glucose_mg_dL\"]\n",
    "    if 'glucose_history_df' in globals():\n",
    "        df = glucose_history_df.get(patient_id)\n",
    "        if df is not None:\n",
    "            return df.copy()\n",
    "    # Synthesize a plausible trend based on seed for determinism\n",
    "    rng = np.random.default_rng(seed=patient_id)\n",
    "    t = pd.date_range(end=pd.Timestamp.today(), periods=60, freq='D')\n",
    "    vals = np.clip(110 + np.cumsum(rng.normal(0, 5, size=len(t))), 70, 300)\n",
    "    return pd.DataFrame({\"timestamp\": t, \"glucose_mg_dL\": vals})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f298000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Model IO Utilities ===\n",
    "from typing import Any, Dict\n",
    "\n",
    "MODEL_PATH = os.path.join(\"models\", \"final_model.joblib\")\n",
    "PIPELINE_PATH = os.path.join(\"models\", \"pipeline_artifacts.joblib\")\n",
    "\n",
    "\n",
    "def save_model_and_pipeline(model: Any, artifacts: Dict[str, Any]) -> Dict[str, str]:\n",
    "    dump(model, MODEL_PATH)\n",
    "    dump(artifacts, PIPELINE_PATH)\n",
    "    return {\"model_path\": MODEL_PATH, \"pipeline_path\": PIPELINE_PATH}\n",
    "\n",
    "\n",
    "def load_model_and_pipeline() -> Dict[str, Any]:\n",
    "    model = load(MODEL_PATH)\n",
    "    artifacts = load(PIPELINE_PATH)\n",
    "    return {\"model\": model, **artifacts}\n",
    "\n",
    "# Try to snapshot artifacts from earlier cells if available\n",
    "try:\n",
    "    pipeline_artifacts = {\n",
    "        \"imputer\": imputer,\n",
    "        \"selector\": selector,\n",
    "        \"label_encoders\": label_encoders if 'label_encoders' in globals() else {},\n",
    "        \"sanitized_feature_names\": sanitized_feature_names,\n",
    "        \"selected_features\": selected_features,\n",
    "        \"feature_name_mapping\": feature_name_mapping,\n",
    "    }\n",
    "    if 'final_model' in globals():\n",
    "        save_model_and_pipeline(final_model, pipeline_artifacts)\n",
    "except Exception as _e:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "223a08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Trend + Recommendation Agent (AutoGen-wrapped) ===\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrendResult:\n",
    "    image_path: str\n",
    "    summary: str\n",
    "    recommendation: str\n",
    "    risk_factor: float\n",
    "\n",
    "\n",
    "class TrendRecommendationAgent:\n",
    "    def __init__(self, llm: LLMClient):\n",
    "        self.llm = llm\n",
    "\n",
    "    def _plot_trend(self, df: pd.DataFrame, patient_id: int) -> str | None:\n",
    "        if df is None or df.empty or 'glucose_mg_dL' not in df.columns:\n",
    "            return None\n",
    "        fig, ax = plt.subplots(figsize=(8, 3))\n",
    "        ax.plot(df['timestamp'], df['glucose_mg_dL'], color='tab:red')\n",
    "        ax.set_title(f\"Glucose Trend - Patient {patient_id}\")\n",
    "        ax.set_ylabel(\"mg/dL\")\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        path = f\"static/trend_{patient_id}.png\"\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(path)\n",
    "        plt.close(fig)\n",
    "        return path\n",
    "\n",
    "    def _model_risk_factor(self, X_selected: np.ndarray, model) -> float:\n",
    "        try:\n",
    "            prob = float(model.predict_proba(X_selected)[:, 1][0])\n",
    "            return round(prob * 100.0, 1)\n",
    "        except Exception:\n",
    "            return 50.0\n",
    "\n",
    "    def run(self, patient_id: int) -> Dict[str, Any]:\n",
    "        # Build glucose trend if available\n",
    "        df_trend = None\n",
    "        try:\n",
    "            df_trend = get_glucose_history(patient_id)\n",
    "        except Exception:\n",
    "            df_trend = None\n",
    "        image_path = self._plot_trend(df_trend, patient_id)\n",
    "        mean = float(df_trend['glucose_mg_dL'].mean()) if df_trend is not None and not df_trend.empty else None\n",
    "        slope = float(np.polyfit(np.arange(len(df_trend)), df_trend['glucose_mg_dL'].values, 1)[0]) if df_trend is not None and len(df_trend) >= 2 else None\n",
    "\n",
    "        # Load model and patient features for all-feature risk\n",
    "        artifacts = load_model_and_pipeline()\n",
    "        model = artifacts['model']\n",
    "        feats = artifacts['selected_features']\n",
    "        rev_map = {v: k for k, v in artifacts.get('feature_name_mapping', {}).items()}\n",
    "        patient = get_patient_vector_from_id(patient_id)\n",
    "        X_selected = patient['X_selected']\n",
    "        risk = self._model_risk_factor(X_selected, model)\n",
    "\n",
    "        # Snapshot of top features (from saved top-20 if available)\n",
    "        top_names = artifacts.get('top_20_selected_names', feats[:10])\n",
    "        # Reconstruct the imputed feature row aligned to feats\n",
    "        try:\n",
    "            # Recreate the imputed feature row\n",
    "            row = df_train_enhanced[df_train_enhanced['patient_id'] == patient_id]\n",
    "            X_full = row.drop(columns=['patient_id', 'readmitted', 'high_risk_90d'], errors='ignore').copy()\n",
    "            def _sanitize_one(n: str) -> str:\n",
    "                return artifacts.get('feature_name_mapping', {}).get(n, sanitize_feature_names([n])[0])\n",
    "            X_full.columns = [_sanitize_one(c) for c in X_full.columns]\n",
    "            X_full = X_full.reindex(columns=artifacts.get('sanitized_feature_names', feats), fill_value=0)\n",
    "            for col, enc in artifacts.get('label_encoders', {}).items():\n",
    "                if col in X_full.columns:\n",
    "                    try:\n",
    "                        X_full[col] = enc.transform(X_full[col].astype(str))\n",
    "                    except Exception:\n",
    "                        X_full[col] = enc.transform([enc.classes_[0]])[0]\n",
    "            X_imp = pd.DataFrame(artifacts['imputer'].transform(X_full), columns=X_full.columns, index=X_full.index)\n",
    "            row_imp = X_imp.iloc[0]\n",
    "            top_snapshot = {rev_map.get(f, f): float(row_imp.get(f, np.nan)) for f in top_names}\n",
    "        except Exception:\n",
    "            top_snapshot = {}\n",
    "\n",
    "        # LLM prompts now reference model risk and key feature snapshot\n",
    "        trend_context = \"\"\n",
    "        if mean is not None and slope is not None:\n",
    "            trend_context = f\"Mean glucose: {mean:.1f} mg/dL, slope: {slope:.3f}/day. Recent: \" \\\n",
    "                            f\"{df_trend['glucose_mg_dL'].tail(5).round(1).tolist()}\"\n",
    "        prompt_summary = (\n",
    "            \"Summarize this patient's overall risk context using model risk and key features.\\n\"\n",
    "            f\"Model risk score (0-100): {risk}.\\n\"\n",
    "            f\"Key feature values: {top_snapshot}.\\n\"\n",
    "            + (f\"Trend: {trend_context}\" if trend_context else \"\")\n",
    "        )\n",
    "        summary = self.llm.generate(prompt_summary)\n",
    "\n",
    "        prompt_reco = (\n",
    "            \"Provide 3-5 plain-language, actionable recommendations for diabetes care, \"\n",
    "            \"grounded in the model risk and key features. Avoid diagnosis.\\n\"\n",
    "            f\"Risk (0-100): {risk}. Key features: {top_snapshot}.\"\n",
    "            + (f\" Trend: {trend_context}\" if trend_context else \"\")\n",
    "        )\n",
    "        recommendation = self.llm.generate(prompt_reco)\n",
    "\n",
    "        return {\"trend_image_path\": image_path, \"trend_summary\": summary, \"recommendation\": recommendation, \"risk_factor\": risk}\n",
    "\n",
    "from autogen import AssistantAgent as _Assistant\n",
    "\n",
    "class TrendAssistant(_Assistant):\n",
    "    def __init__(self, name: str, llm_client: LLMClient):\n",
    "        super().__init__(name)\n",
    "        self.impl = TrendRecommendationAgent(llm_client)\n",
    "\n",
    "    def handle(self, patient_id: int) -> Dict[str, Any]:\n",
    "        return self.impl.run(patient_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae8f166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📥 Loading CSV...\n",
      "📊 CSV shape: (10000, 73)\n",
      "🔧 Computing weighted risk target from CSV...\n",
      "high_risk_90d\n",
      "0    1.0\n",
      "Name: proportion, dtype: float64\n",
      "📈 Training features after enhancement (CSV): 80\n"
     ]
    }
   ],
   "source": [
    "# # === CSV Loader and Weighted Target (replaces HF dataset) ===\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# CSV_PATH = \"risk_prediction_10k_validated_GPU_with_additional_cols.csv\"  # <-- set this\n",
    "\n",
    "# # Map your CSV columns to expected names if needed\n",
    "# COLUMN_MAP = {\n",
    "#     # 'your_patient_id_col': 'patient_id',\n",
    "#     # 'your_readmitted_col': 'readmitted',\n",
    "#     # 'your_emergency_col': 'number_emergency',\n",
    "#     # 'your_inpatient_col': 'number_inpatient',\n",
    "#     # 'your_a1c_gt8_flag_col': 'A1Cresult:>8',\n",
    "#     # 'your_glucose_gt300_flag_col': 'max_glu_serum:>300',\n",
    "# }\n",
    "\n",
    "# USE_CSV_ONLY = True\n",
    "\n",
    "# print(\"📥 Loading CSV...\")\n",
    "# df_train = pd.read_csv(CSV_PATH)\n",
    "# if COLUMN_MAP:\n",
    "#     df_train = df_train.rename(columns=COLUMN_MAP)\n",
    "\n",
    "# # Ensure required columns exist or create defaults\n",
    "# if 'patient_id' not in df_train.columns:\n",
    "#     df_train['patient_id'] = np.arange(1, len(df_train) + 1)\n",
    "\n",
    "# for col, default in [\n",
    "#     ('readmitted', 0),\n",
    "#     ('number_emergency', 0),\n",
    "#     ('number_inpatient', 0),\n",
    "#     ('A1Cresult:>8', 0),\n",
    "#     ('max_glu_serum:>300', 0),\n",
    "# ]:\n",
    "#     if col not in df_train.columns:\n",
    "#         df_train[col] = default\n",
    "\n",
    "# print(f\"📊 CSV shape: {df_train.shape}\")\n",
    "\n",
    "# # Weighted risk target per your spec\n",
    "# print(\"🔧 Computing weighted risk target from CSV...\")\n",
    "# weights = {\n",
    "#     'readmitted': 0.40,\n",
    "#     'number_emergency': 0.20,  # interpreted as high ER utilization flag (>0)\n",
    "#     'number_inpatient': 0.15,  # flag for multiple admissions (>1)\n",
    "#     'A1Cresult:>8': 0.15,\n",
    "#     'max_glu_serum:>300': 0.10,\n",
    "# }\n",
    "\n",
    "# def create_risk_target_from_csv(df: pd.DataFrame) -> pd.Series:\n",
    "#     score = np.zeros(len(df), dtype=float)\n",
    "#     score += df['readmitted'].astype(float) * weights['readmitted']\n",
    "#     score += (df['number_emergency'] > 0).astype(float) * weights['number_emergency']\n",
    "#     score += (df['number_inpatient'] > 1).astype(float) * weights['number_inpatient']\n",
    "#     score += df['A1Cresult:>8'].astype(float) * weights['A1Cresult:>8']\n",
    "#     score += df['max_glu_serum:>300'].astype(float) * weights['max_glu_serum:>300']\n",
    "#     return (score >= 0.5).astype(int)\n",
    "\n",
    "# df_train['high_risk_90d'] = create_risk_target_from_csv(df_train)\n",
    "# print(df_train['high_risk_90d'].value_counts(normalize=True))\n",
    "\n",
    "# # Disable test set\n",
    "# TEST_AVAILABLE = False\n",
    "\n",
    "# # Rebuild enhanced features and proceed\n",
    "# df_train_enhanced = create_advanced_clinical_features(df_train)\n",
    "# print(f\"📈 Training features after enhancement (CSV): {df_train_enhanced.shape[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7630bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Enhanced SHAP Agent (saves top-20 plot) + Orchestrator v2 ===\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class EnhancedSHAPInsightAgent:\n",
    "    def __init__(self, llm: LLMClient):\n",
    "        self.llm = llm\n",
    "\n",
    "    def _compute_shap(self, model, X_selected: np.ndarray) -> np.ndarray:\n",
    "        try:\n",
    "            import shap\n",
    "            # Prefer TreeExplainer when available\n",
    "            if hasattr(model, \"get_booster\") or hasattr(model, \"estimators_\"):\n",
    "                explainer = shap.TreeExplainer(model)\n",
    "                values = explainer.shap_values(X_selected)\n",
    "                if isinstance(values, list):\n",
    "                    values = values[1] if len(values) > 1 else values[0]\n",
    "                return np.array(values).reshape(-1)\n",
    "            # Fallback to KernelExplainer\n",
    "            bg = np.tile(X_selected, (20, 1))\n",
    "            explainer = shap.KernelExplainer(lambda X: model.predict_proba(X)[:, 1], bg)\n",
    "            values = explainer.shap_values(X_selected, nsamples=100)\n",
    "            return np.array(values).reshape(-1)\n",
    "        except Exception:\n",
    "            # Last-resort: zero vector\n",
    "            return np.zeros(X_selected.shape[1], dtype=float)\n",
    "\n",
    "    def run(self, patient_id: int) -> Dict[str, Any]:\n",
    "        artifacts = load_model_and_pipeline()\n",
    "        model = artifacts[\"model\"]\n",
    "        feats: List[str] = artifacts[\"selected_features\"]\n",
    "        rev_map = {v: k for k, v in artifacts.get(\"feature_name_mapping\", {}).items()}\n",
    "\n",
    "        patient = get_patient_vector_from_id(patient_id)\n",
    "        X_selected = patient[\"X_selected\"]\n",
    "\n",
    "        shap_vals = self._compute_shap(model, X_selected)\n",
    "        pairs = list(zip(feats, shap_vals))\n",
    "        pairs_sorted = sorted(pairs, key=lambda x: abs(float(x[1])), reverse=True)\n",
    "        top20 = pairs_sorted[:20]\n",
    "        top20_display = [(rev_map.get(f, f), float(v)) for f, v in top20]\n",
    "\n",
    "        # Save bar plot\n",
    "        os.makedirs(\"static\", exist_ok=True)\n",
    "        shap_path = f\"static/shap_{patient_id}.png\"\n",
    "        names = [n for n, _ in top20_display]\n",
    "        vals = [v for _, v in top20_display]\n",
    "        colors = ['#d62728' if v > 0 else '#1f77b4' for v in vals]\n",
    "        fig, ax = plt.subplots(figsize=(8, 6))\n",
    "        y = np.arange(len(names))\n",
    "        ax.barh(y, vals, color=colors)\n",
    "        ax.set_yticks(y)\n",
    "        ax.set_yticklabels(names)\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(f\"Top-20 SHAP contributions - Patient {patient_id}\")\n",
    "        ax.set_xlabel(\"SHAP value (impact on risk)\")\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(shap_path, dpi=150)\n",
    "        plt.close(fig)\n",
    "\n",
    "        # LLM explanation using top-20\n",
    "        table = \"\\n\".join([f\"- {n}: {v:+.4f}\" for n, v in top20_display])\n",
    "        prompt = (\n",
    "            \"Explain these top-20 factors affecting readmission risk in clear, non-technical language.\\n\"\n",
    "            f\"Top-20 (feature: shap):\\n{table}\\n\"\n",
    "            \"Keep sentences short. Include both increases and decreases in risk.\"\n",
    "        )\n",
    "        explanation = self.llm.generate(prompt)\n",
    "\n",
    "        return {\"shap_insight\": explanation, \"top_contributions\": top20_display, \"shap_image_path\": shap_path}\n",
    "\n",
    "class OrchestratorAgentV2:\n",
    "    def __init__(self, llm: LLMClient):\n",
    "        self.shap_agent = EnhancedSHAPInsightAgent(llm)\n",
    "        self.trend_agent = TrendRecommendationAgent(llm)\n",
    "\n",
    "    def run(self, patient_id: int) -> Dict[str, Any]:\n",
    "        shap_out = self.shap_agent.run(patient_id)\n",
    "        trend_out = self.trend_agent.run(patient_id)\n",
    "        return {\n",
    "            \"shap_insight\": shap_out[\"shap_insight\"],\n",
    "            \"shap_image_path\": shap_out.get(\"shap_image_path\"),\n",
    "            \"trend_image_path\": trend_out[\"trend_image_path\"],\n",
    "            \"trend_summary\": trend_out[\"trend_summary\"],\n",
    "            \"recommendation\": trend_out[\"recommendation\"],\n",
    "            \"risk_factor\": trend_out[\"risk_factor\"],\n",
    "        }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60090b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shap_insight': \"These factors influence the chance of a patient being readmitted to the hospital.  A positive number means higher risk; a negative number means lower risk.\\n\\n**Higher Risk Factors:**\\n\\n* **Many healthcare contacts:** More interactions with the healthcare system increase risk.\\n* **Many emergency room visits:** Frequent ER visits signal higher risk.\\n* **High utilizer:** Patients identified as high utilizers of healthcare have a higher readmission risk.\\n* **Many previous hospital stays:** A history of many hospitalizations increases the chance of another.\\n* **Many diagnoses:** More health problems increase the readmission risk.\\n\\n**Lower Risk Factors:**\\n\\n* **Orthopedic specialty:** Patients treated by orthopedic specialists have a lower risk.\\n* **Fewer medications:** Taking fewer medications lowers the risk.\\n* **Shorter hospital stays:** Shorter stays usually mean lower readmission risk.\\n* **Emergency admission avoidance:** Not being admitted through the ER lowers the risk.\\n* **Fewer lab procedures:** Fewer tests suggest better initial health and lower risk.\\n* **Lower A1C levels:**  Better blood sugar control (A1C below 8) reduces risk.\\n* **Fewer procedures:** Fewer medical procedures performed during the stay lowers risk.\\n* **Lower inpatient care intensity:** Less intensive care needed during a stay lowers risk.\\n* **Insulin use:** Patients using insulin have a slightly lower risk (compared to those not using it).\\n* **Elective admissions:** Planned admissions have a lower risk than emergency admissions.\\n* **Referral admissions:**  Referrals from other doctors are associated with a lower risk.\\n* **Normal or lower blood glucose levels:** Normal blood sugar (not above 300) reduces risk.\\n* **Not taking Metformin:** Patients not on Metformin have a slightly lower risk.\\n* **Simpler insulin regimens:**  Less complex insulin management reduces risk.\\n* **Diabetes diagnosis:**  While seemingly counterintuitive, having a diagnosis of diabetes in the top diagnosis (diag_1) is associated with slightly lower readmission risk in this dataset.  This might be due to other factors correlating with this diagnosis in the dataset.\\n\\n\\nIt's important to remember that this is a statistical association, not a guarantee.  Many factors influence readmission.\\n\",\n",
       " 'shap_image_path': 'static/shap_1.png',\n",
       " 'trend_image_path': 'static/trend_1.png',\n",
       " 'trend_summary': \"This patient presents a moderate risk (model risk score of 16.4), indicating a higher than average likelihood of adverse events.  Key features supporting this include a significant number of medications (27), lab procedures (38), and procedures (3), coupled with multiple diagnoses (7) and a history of inpatient (2) and emergency (1) visits.  While the patient's mean glucose level (108.9 mg/dL) is within a relatively healthy range, the slightly downward trend (-0.399 mg/dL/day) and recent readings suggest potential glucose instability.  The relatively short time in hospital (2 days) and lack of outpatient visits might indicate an acute event leading to the current state.  Overall, the patient's profile suggests a need for close monitoring and proactive management.\\n\",\n",
       " 'recommendation': \"Based on the provided information, here are some actionable recommendations for improving diabetes management:\\n\\n1. **Medication Review:** You're currently taking 27 medications.  This is a high number and could indicate potential drug interactions or unnecessary medications. Schedule an appointment with your doctor or pharmacist to review your medication list and ensure all medications are necessary and appropriately dosed.  This is crucial given your relatively high number of diagnoses (7).\\n\\n2. **Optimize Blood Glucose Control:** Your average blood glucose is trending downward, which is positive (slope: -0.399/day). However, consistent monitoring and proactive adjustments are still important.  Work with your doctor to refine your diabetes management plan, potentially adjusting medication or lifestyle factors, to maintain stable blood glucose levels within your target range.\\n\\n3. **Reduce Hospitalizations and Emergency Room Visits:** Your history includes two inpatient admissions and one emergency room visit recently.  These suggest a need to proactively manage your health to prevent future hospitalizations. Discuss strategies with your doctor to improve your condition's management, address potential underlying issues, and reduce the risk of future hospital visits. Consider joining a diabetes support group.\\n\\n4. **Prioritize Lifestyle Changes (if applicable):** While the provided data doesn't directly address diet and exercise, these are crucial components of diabetes management.  Talk to your doctor or a registered dietitian about developing a healthy eating plan and an exercise program suitable for your health condition.  Even small, consistent changes can make a significant difference.\\n\\n\\n5. **Follow-up Appointments:** Maintain regular check-ups with your healthcare team, including your doctor and potentially other specialists, to monitor your progress, adjust treatment plans as needed, and address any concerns promptly.  Consistent monitoring helps to prevent complications and manage your diabetes effectively.\\n\\n\\n**Important Note:** This information is for general guidance only and does not constitute medical advice.  Always consult with your healthcare provider for personalized recommendations and treatment plans based on your individual health status.\\n\",\n",
       " 'risk_factor': 16.4}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orchestrator_v2 = OrchestratorAgentV2(llm_client)\n",
    "report = orchestrator_v2.run(int(df_train_enhanced['patient_id'].iloc[0]))\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "876fa704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 4 orchestrator reports:\n",
      "{'patient_id': 1,\n",
      " 'recommendation': 'Based on the provided data, here are some actionable '\n",
      "                   'recommendations for improving diabetes care:\\n'\n",
      "                   '\\n'\n",
      "                   \"1. **Medication Review:** You're currently taking 27 \"\n",
      "                   'medications.  This is a high number and may indicate a '\n",
      "                   'need for a medication review with your doctor or '\n",
      "                   'pharmacist.  They can help assess if all medications are '\n",
      "                   'necessary and identify any potential interactions or '\n",
      "                   'redundancies.  This could simplify your routine and '\n",
      "                   'potentially reduce side effects.\\n'\n",
      "                   '\\n'\n",
      "                   '2. **Focus on Preventative Care:** Your history shows '\n",
      "                   'multiple hospitalizations and emergency room visits.  '\n",
      "                   'Proactive measures are crucial.  Discuss preventative '\n",
      "                   'strategies with your doctor, such as regular checkups, '\n",
      "                   'vaccinations (flu, pneumonia), and monitoring for '\n",
      "                   'potential complications.  \\n'\n",
      "                   '\\n'\n",
      "                   '3. **Maintain Consistent Glucose Monitoring:** Your '\n",
      "                   'average glucose levels are within a generally acceptable '\n",
      "                   'range, but the decreasing trend is positive.  Continue '\n",
      "                   'regular glucose monitoring and work with your healthcare '\n",
      "                   \"team to maintain this downward trajectory.  If you're not \"\n",
      "                   'already doing so, consider exploring different monitoring '\n",
      "                   'methods to find what works best for you.\\n'\n",
      "                   '\\n'\n",
      "                   '4. **Address Potential Underlying Issues:**  You have a '\n",
      "                   'substantial number of diagnoses (7).  Addressing these '\n",
      "                   'underlying health issues may improve your overall health '\n",
      "                   'and positively impact your diabetes management.  Work '\n",
      "                   'closely with your doctors to address each condition '\n",
      "                   'effectively.\\n'\n",
      "                   '\\n'\n",
      "                   '5. **Consider Lifestyle Changes (if applicable):** While '\n",
      "                   \"your glucose levels are trending down,  it's vital to \"\n",
      "                   'maintain a healthy lifestyle.  Depending on your current '\n",
      "                   'habits, discuss with your doctor if incorporating dietary '\n",
      "                   'adjustments, increased physical activity, or '\n",
      "                   'stress-reduction techniques would be beneficial.  Small, '\n",
      "                   'sustainable changes can make a big difference.\\n'\n",
      "                   '\\n'\n",
      "                   '\\n'\n",
      "                   '**Important Note:** This information is for general '\n",
      "                   'guidance only and does not constitute medical advice.  '\n",
      "                   'Always consult your doctor or other qualified healthcare '\n",
      "                   'professional for diagnosis and treatment of any medical '\n",
      "                   'condition.\\n',\n",
      " 'risk_factor': 16.4,\n",
      " 'shap_image_path': 'static/shap_1.png',\n",
      " 'shap_insight': \"Here's a simplified explanation of the top 20 factors \"\n",
      "                 'affecting hospital readmission risk:\\n'\n",
      "                 '\\n'\n",
      "                 '**Factors that INCREASE readmission risk:**\\n'\n",
      "                 '\\n'\n",
      "                 '* **More healthcare contacts:**  More doctor visits, etc., '\n",
      "                 'suggest poorer health and higher risk.\\n'\n",
      "                 '* **More emergency room visits:** Frequent ER visits mean '\n",
      "                 'ongoing health problems.\\n'\n",
      "                 '* **Being a \"high utilizer\":**  This means the patient uses '\n",
      "                 'healthcare services a lot.\\n'\n",
      "                 '* **More inpatient stays:**  A history of many hospital '\n",
      "                 'stays increases risk.\\n'\n",
      "                 '* **More diagnoses:** Having several health conditions '\n",
      "                 'raises risk.\\n'\n",
      "                 '\\n'\n",
      "                 '\\n'\n",
      "                 '**Factors that DECREASE readmission risk:**\\n'\n",
      "                 '\\n'\n",
      "                 '* **Orthopedic specialty:** Patients treated by orthopedics '\n",
      "                 'specialists had lower readmission rates.\\n'\n",
      "                 '* **Fewer medications:**  Taking fewer drugs may indicate '\n",
      "                 'better health and lower risk.\\n'\n",
      "                 '* **Shorter hospital stays:** Shorter stays could mean '\n",
      "                 'faster recovery and less risk.\\n'\n",
      "                 '* **Emergency admissions reduced:**  Patients coming from '\n",
      "                 'sources other than the emergency room have a lower risk.\\n'\n",
      "                 '* **Fewer lab procedures:** Less testing might indicate '\n",
      "                 'simpler, less serious conditions.\\n'\n",
      "                 '* **Normal or low A1C levels:**  Good blood sugar control '\n",
      "                 'decreases risk.\\n'\n",
      "                 '* **Fewer procedures:** Fewer medical procedures mean a '\n",
      "                 'lower chance of complications.\\n'\n",
      "                 '* **Lower inpatient intensity of care:** Less intensive care '\n",
      "                 'suggests less severe illness.\\n'\n",
      "                 '* **Insulin use:** Patients using insulin have lower risk '\n",
      "                 '(compared to those not using it).\\n'\n",
      "                 '* **Elective admissions:** Planned admissions generally mean '\n",
      "                 'better preparation and lower risk.\\n'\n",
      "                 '* **Referrals as admission source:** Referrals often '\n",
      "                 'indicate a more planned and coordinated approach.\\n'\n",
      "                 '* **Normal or low blood glucose levels:**  Good blood sugar '\n",
      "                 'control decreases risk.\\n'\n",
      "                 '* **Metformin use:**  Use of this diabetes medication '\n",
      "                 'indicates better health management and lower risk.\\n'\n",
      "                 '* **Simpler insulin regimens:**  Easier insulin management '\n",
      "                 'may suggest better overall health.\\n'\n",
      "                 '* **Not having a diagnosis of diabetes:**  Absence of '\n",
      "                 'diabetes is associated with lower risk.\\n'\n",
      "                 '\\n'\n",
      "                 '\\n'\n",
      "                 '**Important Note:** This is a simplified explanation.  The '\n",
      "                 'actual risk for any individual is complex and depends on '\n",
      "                 'many factors not listed here.\\n',\n",
      " 'trend_image_path': 'static/trend_1.png',\n",
      " 'trend_summary': 'This patient presents a moderate risk (model risk score '\n",
      "                  '16.4 out of 100).  Key features indicating this risk '\n",
      "                  'include a prolonged hospital stay (2 days), extensive lab '\n",
      "                  'procedures (38), multiple procedures (3), high medication '\n",
      "                  'count (27), and a history of multiple hospital admissions '\n",
      "                  '(2 inpatient, 1 emergency).  They also have a significant '\n",
      "                  'number of diagnoses (7).  While their mean glucose level is '\n",
      "                  'relatively controlled (108.9 mg/dL), a slightly negative '\n",
      "                  'trend (-0.399 mg/dL/day) suggests potential improvement but '\n",
      "                  'warrants monitoring.  The presence of diabetes medication '\n",
      "                  \"('diabetesMed': 1.0) further supports the complexity of \"\n",
      "                  \"their case.  The patient's overall clinical picture \"\n",
      "                  'suggests a need for continued observation and management '\n",
      "                  'due to their multimorbidity and complex medical history.\\n'}\n",
      "{'patient_id': 2,\n",
      " 'recommendation': 'Based on the provided information, your risk for '\n",
      "                   'diabetes-related complications appears low. However, '\n",
      "                   'proactive steps can further improve your health. Here are '\n",
      "                   'some recommendations:\\n'\n",
      "                   '\\n'\n",
      "                   '1. **Maintain a Healthy Diet:**  Focus on a balanced diet '\n",
      "                   'rich in fruits, vegetables, and whole grains, limiting '\n",
      "                   'processed foods, sugary drinks, and unhealthy fats.  Given '\n",
      "                   'your relatively high number of medications (11), discuss '\n",
      "                   'your diet with your doctor or a registered dietitian to '\n",
      "                   'ensure your medications and diet are compatible and '\n",
      "                   'support your overall health.\\n'\n",
      "                   '\\n'\n",
      "                   '2. **Regular Physical Activity:** Aim for at least 150 '\n",
      "                   'minutes of moderate-intensity aerobic exercise per week, '\n",
      "                   'spread throughout the week.  This could include brisk '\n",
      "                   'walking, swimming, or cycling.  Consult your doctor before '\n",
      "                   'starting any new exercise program.\\n'\n",
      "                   '\\n'\n",
      "                   '3. **Monitor Blood Glucose:**  Although your average '\n",
      "                   'glucose levels are currently within a healthy range, '\n",
      "                   'consistent monitoring (frequency to be determined by your '\n",
      "                   'doctor) can help identify any potential trends or issues '\n",
      "                   'early.  This may involve regular blood tests or home '\n",
      "                   'glucose monitoring.\\n'\n",
      "                   '\\n'\n",
      "                   '4. **Manage Medications:**  You are currently taking 11 '\n",
      "                   \"medications. This is a relatively high number, and it's \"\n",
      "                   'crucial to work closely with your doctor or pharmacist to '\n",
      "                   \"ensure you understand each medication's purpose, potential \"\n",
      "                   'side effects, and any necessary interactions.  Regular '\n",
      "                   'reviews of your medication regimen are recommended.\\n'\n",
      "                   '\\n'\n",
      "                   '5. **Regular Check-ups:** Schedule regular check-ups with '\n",
      "                   'your doctor to monitor your overall health and address any '\n",
      "                   'concerns.  Given your nine diagnoses, proactive monitoring '\n",
      "                   'is particularly important to ensure all aspects of your '\n",
      "                   'health are well-managed.\\n'\n",
      "                   '\\n'\n",
      "                   '\\n'\n",
      "                   '**Important Note:** This information is for general '\n",
      "                   'guidance only and does not constitute medical advice.  '\n",
      "                   'Always consult your doctor or other qualified healthcare '\n",
      "                   'professional for diagnosis and treatment of any medical '\n",
      "                   'condition.\\n',\n",
      " 'risk_factor': 0.0,\n",
      " 'shap_image_path': 'static/shap_2.png',\n",
      " 'shap_insight': 'These factors influence how likely someone is to be '\n",
      "                 'readmitted to the hospital.  A lower number means lower '\n",
      "                 'risk, while a higher number means higher risk.\\n'\n",
      "                 '\\n'\n",
      "                 '* **More healthcare contacts:** Lower risk.  More contact '\n",
      "                 'with doctors generally means better management.\\n'\n",
      "                 '* **Very high blood sugar (A1C >8):** Lower risk.  This '\n",
      "                 'might be because those with severely high blood sugar are '\n",
      "                 'more closely monitored.\\n'\n",
      "                 '* **Many emergency room visits:** Lower risk.  Frequent ER '\n",
      "                 'visits could indicate proactive care.\\n'\n",
      "                 '* **Very high blood glucose levels (>300):** Lower risk. '\n",
      "                 'Similar to A1C > 8.\\n'\n",
      "                 '* **Many hospital stays:** Lower risk.  Frequent '\n",
      "                 'hospitalizations might signal ongoing, intensive '\n",
      "                 'management.\\n'\n",
      "                 '* **High ratio of ER visits to total visits:** Lower risk.  '\n",
      "                 'Indicates proactive care.\\n'\n",
      "                 '* **Poor diabetes control:** Lower risk.  Similar to points '\n",
      "                 'above; closer monitoring in poorly controlled cases.\\n'\n",
      "                 '* **Normal A1C levels:** Lower risk.  Good blood sugar '\n",
      "                 'control suggests better overall health.\\n'\n",
      "                 '* **High inpatient care intensity:** Lower risk.  Intensive '\n",
      "                 'care often leads to better outcomes.\\n'\n",
      "                 '* **Missing A1C results:** Higher risk.  Lack of testing '\n",
      "                 'indicates poorer management.\\n'\n",
      "                 '* **Missing blood glucose results:** Lower risk.\\n'\n",
      "                 '* **High procedure intensity:** Lower risk.  Suggesting '\n",
      "                 'necessary interventions.\\n'\n",
      "                 '* **High healthcare utilization:** Lower risk.  Could '\n",
      "                 'indicate proactive care.\\n'\n",
      "                 '* **Longer hospital stay:** Higher risk.  Longer stays '\n",
      "                 'suggest more complex issues.\\n'\n",
      "                 '* **Elderly with multiple health problems:** Higher risk.  '\n",
      "                 'Older age and multiple health conditions increase risk.\\n'\n",
      "                 '* **Many lab tests:** Lower risk.  More testing means closer '\n",
      "                 'monitoring.\\n'\n",
      "                 '* **Many procedures:** Higher risk.  Multiple procedures '\n",
      "                 'indicate potentially serious conditions.\\n'\n",
      "                 '* **Diabetes medication use:** Lower risk.  Suggests active '\n",
      "                 'management of diabetes.\\n'\n",
      "                 '* **Many medications:** Lower risk.  Indicates a managed '\n",
      "                 'health condition.\\n'\n",
      "                 '* **Emergency room admission:** Lower risk.\\n'\n",
      "                 '\\n'\n",
      "                 '\\n'\n",
      "                 \"It's important to note that these are statistical \"\n",
      "                 'associations, not guarantees.  Individual situations vary '\n",
      "                 'greatly.\\n',\n",
      " 'trend_image_path': 'static/trend_2.png',\n",
      " 'trend_summary': 'This patient presents with a very low model risk score '\n",
      "                  '(0.0), suggesting a low predicted risk of adverse events '\n",
      "                  'based on the model used.  Despite a relatively long '\n",
      "                  'hospital stay (4 days) and a high number of lab procedures '\n",
      "                  '(48), the patient had no procedures, a moderate number of '\n",
      "                  'medications (11), and no outpatient, emergency, or '\n",
      "                  'inpatient visits prior to this admission.  Nine diagnoses '\n",
      "                  'were recorded, but no medication change was noted and the '\n",
      "                  'patient is not on diabetes medication.  While the mean '\n",
      "                  'glucose level (113.3 mg/dL) is within a generally '\n",
      "                  'acceptable range, a slightly positive upward trend is '\n",
      "                  'observed (slope 0.317/day) with recent readings showing '\n",
      "                  'higher glucose levels (125.9-139.1 mg/dL).  Overall, the '\n",
      "                  'risk profile is complex: low model-predicted risk contrasts '\n",
      "                  'with several factors (multiple diagnoses, high number of '\n",
      "                  'lab procedures, and a slightly increasing glucose trend) '\n",
      "                  'that warrant clinical attention and monitoring.\\n'}\n",
      "{'patient_id': 3,\n",
      " 'recommendation': 'Based on the provided information, it strongly suggests a '\n",
      "                   'need for improved diabetes management.  While I cannot '\n",
      "                   'diagnose, the following recommendations are crucial:\\n'\n",
      "                   '\\n'\n",
      "                   '1. **Increase Engagement with Healthcare Providers:**  The '\n",
      "                   'high number of emergency room visits (3) and '\n",
      "                   'hospitalizations (4) indicates a need for more proactive '\n",
      "                   'care.  Schedule regular appointments with your doctor and '\n",
      "                   'diabetes educator to closely monitor your condition and '\n",
      "                   \"adjust treatment plans as needed.  Don't wait for \"\n",
      "                   'emergencies.\\n'\n",
      "                   '\\n'\n",
      "                   '2. **Medication Review:**  You are taking 15 medications. '\n",
      "                   'This is a significant number. Work with your doctor or '\n",
      "                   'pharmacist to review each medication to ensure they are '\n",
      "                   'all necessary, effective, and not interacting negatively.  '\n",
      "                   'Consider if some medications can be simplified or '\n",
      "                   'adjusted.\\n'\n",
      "                   '\\n'\n",
      "                   '3. **Improve Glucose Control:**  While your average '\n",
      "                   'glucose (106.6 mg/dL) is relatively good, the slightly '\n",
      "                   'upward trend (slope of 0.172/day) needs addressing. This '\n",
      "                   'requires diligent adherence to your prescribed diet and '\n",
      "                   'medication plan, as well as regular self-monitoring of '\n",
      "                   'blood glucose levels.  Discuss strategies for better '\n",
      "                   'control with your doctor.\\n'\n",
      "                   '\\n'\n",
      "                   '4. **Address Underlying Health Issues:**  The high number '\n",
      "                   'of diagnoses (9) suggests that managing your diabetes may '\n",
      "                   'be more challenging due to other health problems.  Working '\n",
      "                   'closely with your healthcare team to address these '\n",
      "                   'concurrently is vital for better overall health and '\n",
      "                   'diabetes management.\\n'\n",
      "                   '\\n'\n",
      "                   '5. **Explore Lifestyle Changes:** While medication is '\n",
      "                   'important, lifestyle modifications can significantly '\n",
      "                   'impact glucose control. Consider working with a registered '\n",
      "                   'dietitian to develop a healthy eating plan and a certified '\n",
      "                   'personal trainer to create a safe and effective exercise '\n",
      "                   'regimen.  Even small changes can make a big difference.\\n',\n",
      " 'risk_factor': 99.1,\n",
      " 'shap_image_path': 'static/shap_3.png',\n",
      " 'shap_insight': \"Here's a simplified explanation of the top 20 factors \"\n",
      "                 'affecting readmission risk:\\n'\n",
      "                 '\\n'\n",
      "                 '**Factors Increasing Risk:**\\n'\n",
      "                 '\\n'\n",
      "                 '* **More healthcare contacts:**  More doctor visits, etc., '\n",
      "                 'mean higher risk.\\n'\n",
      "                 '* **Many emergency visits:** Frequent ER trips increase '\n",
      "                 'risk.\\n'\n",
      "                 '* **Many medications:** Taking lots of drugs increases '\n",
      "                 'risk.\\n'\n",
      "                 '* **Many hospital stays:** Prior hospitalizations predict '\n",
      "                 'future ones.\\n'\n",
      "                 '* **High healthcare utilization:**  Generally using a lot of '\n",
      "                 'healthcare services.\\n'\n",
      "                 '* **Complex medical procedures:**  More intensive procedures '\n",
      "                 'increase risk.\\n'\n",
      "                 '* **Many lab tests:**  Lots of tests suggest more complex '\n",
      "                 'health issues.\\n'\n",
      "                 '* **Long hospital stays:** Longer stays mean higher risk.\\n'\n",
      "                 '* **Many emergency visits relative to total visits:**  A '\n",
      "                 'high proportion of ER visits is risky.\\n'\n",
      "                 '* **Age 70 and over:** Older patients have higher risk.\\n'\n",
      "                 '* **Age 20-50:** This age group has a slightly higher risk '\n",
      "                 'than others.\\n'\n",
      "                 '* **Diabetes diagnosis:** Having diabetes increases risk.\\n'\n",
      "                 '* **Many comorbidities in elderly patients:** Older people '\n",
      "                 'with multiple health problems have higher risk.\\n'\n",
      "                 '* **Recent change in health status:** Recent worsening of '\n",
      "                 'health increases risk.\\n'\n",
      "                 '\\n'\n",
      "                 '**Factors Decreasing Risk:**\\n'\n",
      "                 '\\n'\n",
      "                 '* **High A1C levels (above 8):**  Surprisingly, very high '\n",
      "                 'blood sugar levels (A1C) are associated with slightly lower '\n",
      "                 'risk, possibly due to more aggressive management.\\n'\n",
      "                 '* **Poor diabetes control:**  While diabetes itself '\n",
      "                 'increases risk, *poorly* controlled diabetes (surprisingly) '\n",
      "                 \"shows a slightly lower risk. This might be due to the data's \"\n",
      "                 'limitations or complex interactions between factors.\\n'\n",
      "                 '* **Very high blood glucose levels (over 300):** Similar to '\n",
      "                 'the A1C finding, extremely high blood sugar is linked with '\n",
      "                 'slightly lower risk. This likely warrants further '\n",
      "                 'investigation.\\n'\n",
      "                 '* **Missing A1C test results:**  Lack of A1C information '\n",
      "                 'shows slightly lower risk, likely due to the patients these '\n",
      "                 'data represent.\\n'\n",
      "                 '* **Emergency room admission:** Being admitted through the '\n",
      "                 'ER slightly decreases risk.  \\n'\n",
      "                 '* **Many procedures:** Fewer procedures mean lower risk.\\n'\n",
      "                 '\\n'\n",
      "                 '\\n'\n",
      "                 '**Important Note:** These are statistical associations, not '\n",
      "                 \"guarantees.  One factor alone doesn't determine \"\n",
      "                 'readmission.  Many factors interact to influence the overall '\n",
      "                 'risk.\\n',\n",
      " 'trend_image_path': 'static/trend_3.png',\n",
      " 'trend_summary': 'This patient presents an extremely high risk (model risk '\n",
      "                  'score: 99.1) of an adverse event.  Key features '\n",
      "                  'contributing to this high risk include: a prolonged history '\n",
      "                  'of multiple hospitalizations (4 inpatient, 3 emergency), a '\n",
      "                  'high number of diagnoses (9),  a substantial number of '\n",
      "                  'medications (15) and lab procedures (28),  and a history of '\n",
      "                  \"diabetes requiring medication. While the patient's mean \"\n",
      "                  'glucose is relatively well-controlled (106.6 mg/dL), a '\n",
      "                  'slightly positive upward trend (0.172 mg/dL/day) is '\n",
      "                  'observed.  The absence of outpatient and procedures, along '\n",
      "                  'with a lack of change noted (possibly indicating a lack of '\n",
      "                  'recent intervention response), further contribute to the '\n",
      "                  'elevated risk profile.\\n'}\n",
      "{'patient_id': 4,\n",
      " 'recommendation': 'Based on the provided data, your glucose levels appear '\n",
      "                   'well-managed. However,  the following recommendations can '\n",
      "                   'help maintain this and further improve your overall '\n",
      "                   'health:\\n'\n",
      "                   '\\n'\n",
      "                   '1. **Maintain your medication regimen:**  You are '\n",
      "                   \"currently taking 10 medications.  It's crucial to continue \"\n",
      "                   'taking all prescribed medications as directed by your '\n",
      "                   \"doctor.  Don't adjust dosages or stop taking any \"\n",
      "                   'medication without consulting your doctor.\\n'\n",
      "                   '\\n'\n",
      "                   '2. **Continue monitoring your blood glucose:** Your recent '\n",
      "                   'glucose readings are encouraging, showing a downward '\n",
      "                   'trend. Continue regularly monitoring your blood glucose as '\n",
      "                   'instructed by your healthcare provider to maintain '\n",
      "                   'awareness and promptly address any significant changes.\\n'\n",
      "                   '\\n'\n",
      "                   '3. **Focus on a healthy diet and regular exercise:**  Even '\n",
      "                   'with good glucose control, a balanced diet and regular '\n",
      "                   'physical activity are vital for overall health and '\n",
      "                   'preventing future complications. Consult a nutritionist or '\n",
      "                   'dietitian for personalized guidance on dietary choices. '\n",
      "                   'Aim for at least 150 minutes of moderate-intensity aerobic '\n",
      "                   'exercise per week.\\n'\n",
      "                   '\\n'\n",
      "                   '4. **Schedule regular check-ups:** Given your relatively '\n",
      "                   'high number of diagnoses (7) and the significant number of '\n",
      "                   'lab procedures (44), maintaining regular communication and '\n",
      "                   'check-ups with your healthcare team is essential. This '\n",
      "                   'allows for proactive monitoring and adjustments to your '\n",
      "                   'care plan as needed.\\n'\n",
      "                   '\\n'\n",
      "                   '\\n'\n",
      "                   '5. **Address the underlying conditions:** The high number '\n",
      "                   'of diagnoses suggests the presence of other health '\n",
      "                   'conditions.  Working with your doctor to manage these '\n",
      "                   'conditions effectively can indirectly improve your '\n",
      "                   'diabetes management.  This may involve specialists '\n",
      "                   'depending on the diagnoses.\\n',\n",
      " 'risk_factor': 0.0,\n",
      " 'shap_image_path': 'static/shap_4.png',\n",
      " 'shap_insight': 'These factors influence how likely someone is to be '\n",
      "                 'readmitted to the hospital.  A negative number means it '\n",
      "                 '*decreases* the risk, while a positive number *increases* '\n",
      "                 'it:\\n'\n",
      "                 '\\n'\n",
      "                 '* **More healthcare contacts:** Fewer contacts lower '\n",
      "                 'readmission risk.\\n'\n",
      "                 '* **High A1C levels (blood sugar):**  High A1C significantly '\n",
      "                 'decreases risk.\\n'\n",
      "                 '* **Many emergency room visits:** Fewer ER visits mean lower '\n",
      "                 'risk.\\n'\n",
      "                 '* **Very high blood sugar readings:** Lower readings lower '\n",
      "                 'risk.\\n'\n",
      "                 '* **Many hospital stays:** Fewer hospitalizations reduce '\n",
      "                 'risk.\\n'\n",
      "                 '* **High ratio of ER visits to total visits:** A lower ratio '\n",
      "                 'lowers risk.\\n'\n",
      "                 '* **Poor diabetes control:** Better control reduces risk.\\n'\n",
      "                 '* **High inpatient care intensity:** Lower intensity lowers '\n",
      "                 'risk.\\n'\n",
      "                 '* **Missing blood sugar readings:** Having readings reduces '\n",
      "                 'risk.\\n'\n",
      "                 '* **Many medications:** Fewer medications are linked to '\n",
      "                 'slightly lower risk.\\n'\n",
      "                 '* **High healthcare utilization:** Lower utilization '\n",
      "                 'slightly lowers risk.\\n'\n",
      "                 '* **Many diagnoses:** More diagnoses slightly increase '\n",
      "                 'risk.\\n'\n",
      "                 '* **No insulin use:** Insulin use is slightly associated '\n",
      "                 'with lower risk.\\n'\n",
      "                 '* **Many lab tests:** Fewer tests slightly lower risk.\\n'\n",
      "                 '* **Moderate diabetes control:** Better control reduces '\n",
      "                 'risk.\\n'\n",
      "                 '* **Elderly with many health problems:** Fewer problems '\n",
      "                 'reduce risk.\\n'\n",
      "                 '* **Emergency room admissions:** Fewer emergency admissions '\n",
      "                 'lower risk.\\n'\n",
      "                 '* **Missing A1C results:** Having results slightly lowers '\n",
      "                 'risk.\\n'\n",
      "                 '* **Many medical procedures:** More procedures slightly '\n",
      "                 'increase risk.\\n'\n",
      "                 '* **Referrals to hospital:** Referrals slightly increase '\n",
      "                 'risk.\\n',\n",
      " 'trend_image_path': 'static/trend_4.png',\n",
      " 'trend_summary': 'This patient presents with a very low model risk score '\n",
      "                  '(0.0), suggesting a low predicted risk of adverse events '\n",
      "                  'according to the model used.  Despite a significant number '\n",
      "                  'of diagnoses (7) and medications (10), and a high number of '\n",
      "                  'lab procedures (44), other factors contribute to the low '\n",
      "                  'risk.  These factors include a relatively short time in '\n",
      "                  'hospital (4 days), no prior inpatient, outpatient, or '\n",
      "                  'emergency room visits,  no procedures performed, and stable '\n",
      "                  'glucose levels showing a slightly decreasing trend (-0.573 '\n",
      "                  'mg/dL per day) from a relatively low mean of 95.8 mg/dL.  '\n",
      "                  'The patient is also taking diabetes medication (diabetesMed '\n",
      "                  '= 1.0).  In summary, while the patient has multiple '\n",
      "                  'diagnoses and is on several medications, the lack of recent '\n",
      "                  'adverse events, combined with the low risk score, indicates '\n",
      "                  'a currently low-risk profile.\\n'}\n"
     ]
    }
   ],
   "source": [
    "# === Generate 4 orchestrator V2 outputs for 4 different patients ===\n",
    "from pprint import pprint\n",
    "\n",
    "orchestrator_v2 = OrchestratorAgentV2(llm_client)\n",
    "patient_ids = df_train_enhanced['patient_id'].drop_duplicates().astype(int).head(4).tolist()\n",
    "outputs = []\n",
    "for pid in patient_ids:\n",
    "    try:\n",
    "        out = orchestrator_v2.run(pid)\n",
    "        outputs.append({\"patient_id\": pid, **out})\n",
    "    except Exception as e:\n",
    "        outputs.append({\"patient_id\": pid, \"error\": str(e)})\n",
    "\n",
    "print(\"Generated 4 orchestrator reports:\")\n",
    "for o in outputs:\n",
    "    pprint(o)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
